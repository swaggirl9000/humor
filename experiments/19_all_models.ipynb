{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"..\")\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from thefuzz import fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from humor.bipartite_metric import bipartite_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv('/home/ada/humor/data/stand_up_dataset/standup_data.csv')\n",
    "gemma = pd.read_csv('/home/ada/humor/data/stand_up_dataset/gemma_answers.csv')\n",
    "phi_model = pd.read_csv(\"/home/ada/humor/data/stand_up_dataset/phi3_mini_quotes.csv\")\n",
    "gemma2 = pd.read_csv(\"/home/ada/humor/data/stand_up_dataset/gemma2_2 - gemma2 - gemma2.csv\")\n",
    "llama = pd.read_csv(\"/home/ada/humor/data/stand_up_dataset/llama - llama.csv\")\n",
    "chatgpt = pd.read_csv(\"\")\n",
    "claude = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_metric = bipartite_metric(gemma, ground_truth)\n",
    "print(\"Gemma Model:\", gemma_metric.select_dtypes(include='number').mean())\n",
    "\n",
    "phi_metric = bipartite_metric(phi_model, ground_truth)\n",
    "print(\"Phi Model:\", phi_metric.select_dtypes(include='number').mean())\n",
    "\n",
    "gemma2_metric = bipartite_metric(gemma2, ground_truth)\n",
    "print(\"Gemma2 Model:\", gemma2_metric.select_dtypes(include='number').mean())\n",
    "\n",
    "llama_metric = bipartite_metric(llama, ground_truth)\n",
    "print(\"Llama Model:\",llama_metric.select_dtypes(include='number').mean())\n",
    "\n",
    "chat_metric = bipartite_metric(chatgpt, ground_truth)\n",
    "print(\"Gemma2 Model:\", chat_metric.select_dtypes(include='number').mean())\n",
    "\n",
    "claude_metric = bipartite_metric(claude, ground_truth)\n",
    "print(\"Llama Model:\",claude_metric.select_dtypes(include='number').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma = gemma_metric.assign(model=\"gemma\")\n",
    "phi = phi_metric.assign(model=\"phi\")\n",
    "gemma2 = gemma2_metric.assign(model = \"gemma2\")\n",
    "llama = llama_metric.assign(model = \"llama\")\n",
    "chat = chat_metric.assign(model = \"chat\")\n",
    "claude = claude_metric.assign(model = \"claude\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "plt.figure(figsize=(5, 5))  \n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "df = pd.concat([gemma, phi, gemma2, llama, chat, claude]).reset_index(drop=True)\n",
    "\n",
    "plot = sns.displot(\n",
    "    df, x=\"score\", hue=\"model\", kind=\"kde\",\n",
    "    linewidth=2 \n",
    ")\n",
    "\n",
    "plot.set_axis_labels(\"Score (%)\", \"Count\", fontsize=12)\n",
    "\n",
    "plot._legend.get_title().set_fontsize(12) \n",
    "for text in plot._legend.texts:\n",
    "    text.set_fontsize(12) \n",
    "plt.xlim(0,100)\n",
    "\n",
    "plot.savefig(\"experiment_02.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
