{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM humor detection with Subspace based metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ada/humor/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "MODEL_ID = \"google/gemma-2-2b-it\"\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"cuda:0\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    output_hidden_states=True  # Enable hidden states output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv('../data/stand_up_dataset/standup_data.csv')\n",
    "transcript = pd.read_csv('../data/stand_up_dataset/standup_transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = [\n",
    "    \"Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    \"The following is a stand-up comedy transcript. When performed in front of a live audience, which jokes do you think made the audience laugh?  List of quotes:\",\n",
    "    \"You are a person who enjoys aggressive humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    \"You are a person who enjoys self-enhancing humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"You are a person who enjoys self-deprecating humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"You are a person who enjoys dark humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"You are a person who enjoys affiliative humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"The following is a stand-up comedy transcript. What are the funniest punchlines from the transcript. List of quotes:\",\n",
    "    # \"Below is a transcript from a stand-up comedy routine. Analyze the transcript and extract the quotes that are most likely to have made the audience laugh. List of quotes:\",\n",
    "    # \"The following is a stand-up comedy transcript. When preformed in front of a live audience, which jokes do you think made the audience laugh? List of quotes:\",\n",
    "    # \"Pretend that you are a stand-up comedian reading the following stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"Pretend that you are a stand-up comedy fan reading the following stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"Pretend that you are a stand-up comedy critic reading the following stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    #\"Analyze the stand-up comedy transcript below. Which lines and punchlines do you think delivered the biggest laughs to the audience? List of quotes:\", \n",
    "    #\"As a person who enjoys witty, intellectual humor, extract the key humorous lines and punchlines from this stand-up comedy transcript. Focus on the quotes that demonstrate clever wordplay or insights. List of quotes:\",\n",
    "    #\"This is a transcript from a stand-up routine. Identify the lines and punchlines that likely had the strongest comedic impact during the performance. List of quotes:\",\n",
    "    #\"Pretend you're an audience member at this stand-up show. Which lines do you think got the biggest laughs? Focus on key moments of humor. List of quotes:\",\n",
    "    #\"This is a transcript of a live stand-up performance. Which quotes do you believe would have resonated the most with the audience? Focus on key punchlines. List of quotes:\",\n",
    "    #\"Imagine you are a comedian reviewing this stand-up routine. Identify the funniest moments and lines where the punchlines landed the hardest. List of quotes:\",\n",
    "    #\"Read through the stand-up comedy transcript and extract the lines that best capture the humor and timing of the performance. Focus on punchlines that likely had the audience laughing. List of quotes:\",\n",
    "    #\"This is a stand-up comedy transcript. Analyze the content and extract the lines that most effectively build up to or deliver punchlines. List of quotes:\",\n",
    "    #\"Pretend you're watching this performance live. What do you think were the standout comedic lines and punchlines that elicited the loudest laughs? List of quotes:\",\n",
    "    #\"Imagine you are writing a review of this stand-up performance. What lines and punchlines would you highlight as the funniest moments? List of quotes:\"\n",
    "]\n",
    "\n",
    "CONTENTS = [\n",
    "    \"\",\n",
    "    \"Sure, here are the key humorous lines:\",\n",
    "    \"Here are some lines and punchlines that could be funny:\",\n",
    "    \"Got it! Here are the main punchlines and comedic highlights:\",\n",
    "    \"Here’s a selection of the funniest quotes from the transcript:\",\n",
    "    \"I've picked out the key humorous moments for you:\",\n",
    "    \"Below are the standout lines and punchlines from the performance:\",\n",
    "    \"Here's a breakdown of the top quotes that likely got the biggest laughs:\",\n",
    "    \"Take a look at these key comedic lines from the routine:\",\n",
    "    \"Here’s a list of the most memorable punchlines from the set:\",\n",
    "    \"Check out these quotes—some of the best comedic moments from the transcript:\",\n",
    "    \"Here are the funniest moments and punchlines I found in the transcript:\",\n",
    "    \"Here’s what I’ve identified as the standout lines and punchlines in this comedy routine:\" \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2448, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = ground_truth.groupby(\"comedian\")[\"sentence\"].apply(list).apply(lambda sentences: \"\\n\".join([f\"{i + 1}. {s}\" for i, s in enumerate(sentences)]))\n",
    "df = transcript.set_index(\"comedian\").join(gt).rename(columns={\"sentence\": \"ground_truth\"})\n",
    "\n",
    "df[\"instruction\"] = [INSTRUCTIONS] * len(df)\n",
    "df = df.explode(\"instruction\")\n",
    "df[\"content\"] = [CONTENTS] * len(df)\n",
    "df = df.explode(\"content\")\n",
    "\n",
    "def gt_chat_template(row):\n",
    "    return tokenizer.apply_chat_template([\n",
    "        # {\"role\": \"system\", \"content\": \"\"},\n",
    "        {\"role\": \"user\", \"content\": row[\"instruction\"] + \"\\n\" + row[\"transcript\"]},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"content\"] + \"\\n\" + row[\"ground_truth\"]},\n",
    "    ], tokenize=False)\n",
    "\n",
    "df[\"gt_input\"] = df.apply(gt_chat_template, axis=1)\n",
    "\n",
    "def model_chat_template(row):\n",
    "    return tokenizer.apply_chat_template([\n",
    "        # {\"role\": \"system\", \"content\": \"\"},\n",
    "        {\"role\": \"user\", \"content\": row[\"instruction\"] + \"\\n\" + row[\"transcript\"]},\n",
    "    ], tokenize=False)\n",
    "\n",
    "df[\"model_input\"] = df.apply(model_chat_template, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "100%|██████████| 51/51 [00:04<00:00, 10.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# use unembedding tokenization form\n",
    "def get_gt_representation(batch_of_strs: list[str], number_of_tokens: int = 128) -> torch.Tensor:\n",
    "    inputs = tokenizer(batch_of_strs, return_tensors=\"pt\", padding=True, truncation=False).to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        return model(**inputs).hidden_states[-1][:, -number_of_tokens:].flatten(1)\n",
    "\n",
    "gt_representations = {\n",
    "    comedian: get_gt_representation(batch.tolist())\n",
    "    for comedian, batch in tqdm(df.groupby(\"comedian\")[\"model_input\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51 [00:00<?, ?it/s]The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\n",
      "100%|██████████| 51/51 [01:49<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_output_representation(batch_of_strs: list[str], number_of_tokens: int = 128) -> torch.Tensor:\n",
    "    inputs = tokenizer(batch_of_strs, return_tensors=\"pt\", padding=True, truncation=False).to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        return model(input_ids=model.generate(**inputs, max_new_tokens=128)).hidden_states[-1][:, -number_of_tokens:].flatten(1)\n",
    "\n",
    "output_representations = {\n",
    "    comedian: get_output_representation(batch.tolist())\n",
    "    for comedian, batch in tqdm(df.groupby(\"comedian\")[\"gt_input\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 294912])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_representations[\"Ali_Wong\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 294912])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_representations[\"Ali_Wong\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 239.06it/s]\n"
     ]
    }
   ],
   "source": [
    "def make_subspace(data: torch.FloatTensor, q: int = 3) -> torch.Tensor:\n",
    "    data = torch.nn.functional.normalize(data, p=2, dim=-1)\n",
    "    data = data - data.mean(0, keepdim=True)\n",
    "    *_, Vh = torch.pca_lowrank(data, q=q)\n",
    "    return Vh\n",
    "\n",
    "scores = {}\n",
    "for comedian in tqdm(gt_representations.keys()):\n",
    "    gt_reference_subspace = make_subspace(gt_representations[comedian].float())\n",
    "    out_reference_subspace = make_subspace(output_representations[comedian].float())\n",
    "\n",
    "    A = gt_reference_subspace.mT @ out_reference_subspace\n",
    "    scores[comedian] = (A.mT @ A).trace() / A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<bos><start_of_turn>user\\nExtract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\\nThe last time I was at home in San Francisco, I was trying to help her get rid of shit. Don’t ever do that with your mom. It was like the worst experience of my life. It was so emotional. We were screaming and fighting and yelling and it all came to a climax when she refused to let go of a Texas Instruments TI-82… manual. The manual. She don’t even know… where the calculator is. Those of you under 25 probably don’t know what that calculator is. It was this calculator that bamboozled my generation. We were all required to buy it when we were in eight grade. It cost like $200. And everybody thought it was like this Judy Jetson’s laptop from the future. All because what? It could graph. It was like the Tesla of my time. And my mom got so emotional about the manual and she was like, “You never know when you might need this.” And I was like, “But… I do know… that I’m gonna have to clean all this shit up when you die.” “And I’m not trying to be a procrastinator anymore. Because according to Deepak-Oprah, that’s not the way for me to achieve my optimum level of success.”<end_of_turn>\\n<start_of_turn>model\\nSure, here are the key humorous lines:\\n1. We were screaming and fighting and yelling and it all came to a climax when she refused to let go of a Texas Instruments TI-82... manual.\\n2. We were all required to buy it when we were in eight grade. It cost like $200.\\n3. All because what? It could graph.\\n4. It was like the Tesla of my time.\\n5. I do know... that I'm gonna have to clean all this shit up when you die.\\n6. Because according to Deepak-Oprah, that's not the way for me to achieve my optimum level of success.<end_of_turn>\\n\",\n",
       " \"<bos><start_of_turn>user\\nThe following is a stand-up comedy transcript. When performed in front of a live audience, which jokes do you think made the audience laugh?  List of quotes:\\nThe last time I was at home in San Francisco, I was trying to help her get rid of shit. Don’t ever do that with your mom. It was like the worst experience of my life. It was so emotional. We were screaming and fighting and yelling and it all came to a climax when she refused to let go of a Texas Instruments TI-82… manual. The manual. She don’t even know… where the calculator is. Those of you under 25 probably don’t know what that calculator is. It was this calculator that bamboozled my generation. We were all required to buy it when we were in eight grade. It cost like $200. And everybody thought it was like this Judy Jetson’s laptop from the future. All because what? It could graph. It was like the Tesla of my time. And my mom got so emotional about the manual and she was like, “You never know when you might need this.” And I was like, “But… I do know… that I’m gonna have to clean all this shit up when you die.” “And I’m not trying to be a procrastinator anymore. Because according to Deepak-Oprah, that’s not the way for me to achieve my optimum level of success.”<end_of_turn>\\n<start_of_turn>model\\nSure, here are the key humorous lines:\\n1. We were screaming and fighting and yelling and it all came to a climax when she refused to let go of a Texas Instruments TI-82... manual.\\n2. We were all required to buy it when we were in eight grade. It cost like $200.\\n3. All because what? It could graph.\\n4. It was like the Tesla of my time.\\n5. I do know... that I'm gonna have to clean all this shit up when you die.\\n6. Because according to Deepak-Oprah, that's not the way for me to achieve my optimum level of success.<end_of_turn>\\n\",\n",
       " \"<bos><start_of_turn>user\\nYou are a person who enjoys aggressive humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\\nThe last time I was at home in San Francisco, I was trying to help her get rid of shit. Don’t ever do that with your mom. It was like the worst experience of my life. It was so emotional. We were screaming and fighting and yelling and it all came to a climax when she refused to let go of a Texas Instruments TI-82… manual. The manual. She don’t even know… where the calculator is. Those of you under 25 probably don’t know what that calculator is. It was this calculator that bamboozled my generation. We were all required to buy it when we were in eight grade. It cost like $200. And everybody thought it was like this Judy Jetson’s laptop from the future. All because what? It could graph. It was like the Tesla of my time. And my mom got so emotional about the manual and she was like, “You never know when you might need this.” And I was like, “But… I do know… that I’m gonna have to clean all this shit up when you die.” “And I’m not trying to be a procrastinator anymore. Because according to Deepak-Oprah, that’s not the way for me to achieve my optimum level of success.”<end_of_turn>\\n<start_of_turn>model\\nSure, here are the key humorous lines:\\n1. We were screaming and fighting and yelling and it all came to a climax when she refused to let go of a Texas Instruments TI-82... manual.\\n2. We were all required to buy it when we were in eight grade. It cost like $200.\\n3. All because what? It could graph.\\n4. It was like the Tesla of my time.\\n5. I do know... that I'm gonna have to clean all this shit up when you die.\\n6. Because according to Deepak-Oprah, that's not the way for me to achieve my optimum level of success.<end_of_turn>\\n\",\n",
       " \"<bos><start_of_turn>user\\nYou are a person who enjoys self-enhancing humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\\nThe last time I was at home in San Francisco, I was trying to help her get rid of shit. Don’t ever do that with your mom. It was like the worst experience of my life. It was so emotional. We were screaming and fighting and yelling and it all came to a climax when she refused to let go of a Texas Instruments TI-82… manual. The manual. She don’t even know… where the calculator is. Those of you under 25 probably don’t know what that calculator is. It was this calculator that bamboozled my generation. We were all required to buy it when we were in eight grade. It cost like $200. And everybody thought it was like this Judy Jetson’s laptop from the future. All because what? It could graph. It was like the Tesla of my time. And my mom got so emotional about the manual and she was like, “You never know when you might need this.” And I was like, “But… I do know… that I’m gonna have to clean all this shit up when you die.” “And I’m not trying to be a procrastinator anymore. Because according to Deepak-Oprah, that’s not the way for me to achieve my optimum level of success.”<end_of_turn>\\n<start_of_turn>model\\nSure, here are the key humorous lines:\\n1. We were screaming and fighting and yelling and it all came to a climax when she refused to let go of a Texas Instruments TI-82... manual.\\n2. We were all required to buy it when we were in eight grade. It cost like $200.\\n3. All because what? It could graph.\\n4. It was like the Tesla of my time.\\n5. I do know... that I'm gonna have to clean all this shit up when you die.\\n6. Because according to Deepak-Oprah, that's not the way for me to achieve my optimum level of success.<end_of_turn>\\n\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\"Ali_Wong\", \"gt_input\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0282, 0.0282, 0.0282, 0.0282], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = gt_representations[\"Ali_Wong\"].float()\n",
    "data = torch.nn.functional.normalize(data, p=2, dim=-1)\n",
    "\n",
    "(data @ make_subspace(data)).square().mean(-1).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_representations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gt_reference_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_representations\u001b[49m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m comedian, rep \u001b[38;5;129;01min\u001b[39;00m i\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      4\u001b[0m         gt_references \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(rep)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_representations' is not defined"
     ]
    }
   ],
   "source": [
    "gt_reference_list = []\n",
    "for i in all_representations:\n",
    "    for comedian, rep in i.items():\n",
    "        gt_references = torch.stack(rep)\n",
    "        *_, gt_reference_subspace = torch.pca_lowrank(gt_references.float(), q=10)\n",
    "        gt_reference_list.append({comedian: gt_reference_subspace})\n",
    "    \n",
    "# gt_reference_subspace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = [f\"{inst}\\n{text}\\n\" for inst, text in product(INSTRUCTIONS, TRANSCRIPTS)]\n",
    "\n",
    "#inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "#with torch.inference_mode():\n",
    "    #outputs = model(input_ids=model.generate(**inputs, max_new_tokens=128))\n",
    "\n",
    "\n",
    "# representations = torch.cat(outputs.hidden_states)[-1, -16:].flatten()\n",
    "# all_representations.append(representation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
