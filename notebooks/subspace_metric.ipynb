{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM humor detection with Subspace based metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ada/humor/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "MODEL_ID = \"google/gemma-2-2b-it\"\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"cuda:0\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    output_hidden_states=True  # Enable hidden states output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv('./data/stand_up_dataset/standup_data.csv')\n",
    "transcript = pd.read_csv('./data/stand_up_dataset/standup_transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = [\n",
    "    \"Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    \"The following is a stand-up comedy transcript. When performed in front of a live audience, which jokes do you think made the audience laugh?  List of quotes:\",\n",
    "    \"You are a person who enjoys aggressive humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    \"You are a person who enjoys self-enhancing humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"You are a person who enjoys self-deprecating humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"You are a person who enjoys dark humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"You are a person who enjoys affiliative humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"The following is a stand-up comedy transcript. What are the funniest punchlines from the transcript. List of quotes:\",\n",
    "    # \"Below is a transcript from a stand-up comedy routine. Analyze the transcript and extract the quotes that are most likely to have made the audience laugh. List of quotes:\",\n",
    "    # \"The following is a stand-up comedy transcript. When preformed in front of a live audience, which jokes do you think made the audience laugh? List of quotes:\",\n",
    "    # \"Pretend that you are a stand-up comedian reading the following stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"Pretend that you are a stand-up comedy fan reading the following stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"Pretend that you are a stand-up comedy critic reading the following stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    #\"Analyze the stand-up comedy transcript below. Which lines and punchlines do you think delivered the biggest laughs to the audience? List of quotes:\", \n",
    "    #\"As a person who enjoys witty, intellectual humor, extract the key humorous lines and punchlines from this stand-up comedy transcript. Focus on the quotes that demonstrate clever wordplay or insights. List of quotes:\",\n",
    "    #\"This is a transcript from a stand-up routine. Identify the lines and punchlines that likely had the strongest comedic impact during the performance. List of quotes:\",\n",
    "    #\"Pretend you're an audience member at this stand-up show. Which lines do you think got the biggest laughs? Focus on key moments of humor. List of quotes:\",\n",
    "    #\"This is a transcript of a live stand-up performance. Which quotes do you believe would have resonated the most with the audience? Focus on key punchlines. List of quotes:\",\n",
    "    #\"Imagine you are a comedian reviewing this stand-up routine. Identify the funniest moments and lines where the punchlines landed the hardest. List of quotes:\",\n",
    "    #\"Read through the stand-up comedy transcript and extract the lines that best capture the humor and timing of the performance. Focus on punchlines that likely had the audience laughing. List of quotes:\",\n",
    "    #\"This is a stand-up comedy transcript. Analyze the content and extract the lines that most effectively build up to or deliver punchlines. List of quotes:\",\n",
    "    #\"Pretend you're watching this performance live. What do you think were the standout comedic lines and punchlines that elicited the loudest laughs? List of quotes:\",\n",
    "    #\"Imagine you are writing a review of this stand-up performance. What lines and punchlines would you highlight as the funniest moments? List of quotes:\"\n",
    "]\n",
    "\n",
    "CONTENTS = [\n",
    "    \"\",\n",
    "    \"Sure, here are the key humorous lines:\",\n",
    "    \"Here are some lines and punchlines that could be funny:\",\n",
    "    \"Got it! Here are the main punchlines and comedic highlights:\",\n",
    "    # \"Here's a selection of the funniest quotes from the transcript:\",\n",
    "    # \"I've picked out the key humorous moments for you:\",\n",
    "    # \"Below are the standout lines and punchlines from the performance:\",\n",
    "    # \"Here's a breakdown of the top quotes that likely got the biggest laughs:\",\n",
    "    # \"Take a look at these key comedic lines from the routine:\",\n",
    "    # \"Here's a list of the most memorable punchlines from the set:\",\n",
    "    # \"Check out these quotes—some of the best comedic moments from the transcript:\",\n",
    "    # \"Here are the funniest moments and punchlines I found in the transcript:\",\n",
    "    # \"Here's what I've identified as the standout lines and punchlines in this comedy routine:\" \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2448, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = ground_truth.groupby(\"comedian\")[\"sentence\"].apply(list).apply(lambda sentences: \"\\n\".join([f\"{i + 1}. {s}\" for i, s in enumerate(sentences)]))\n",
    "df = transcript.set_index(\"comedian\").join(gt).rename(columns={\"sentence\": \"ground_truth\"})\n",
    "\n",
    "df[\"instruction\"] = [INSTRUCTIONS] * len(df)\n",
    "df = df.explode(\"instruction\")\n",
    "df[\"content\"] = [CONTENTS] * len(df)\n",
    "df = df.explode(\"content\")\n",
    "\n",
    "def gt_chat_template(row):\n",
    "    return tokenizer.apply_chat_template([\n",
    "        # {\"role\": \"system\", \"content\": \"\"},\n",
    "        {\"role\": \"user\", \"content\": row[\"instruction\"] + \"\\n\" + row[\"transcript\"]},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"content\"] + \"\\n\" + row[\"ground_truth\"]},\n",
    "    ], tokenize=False)\n",
    "\n",
    "df[\"gt_input\"] = df.apply(gt_chat_template, axis=1)\n",
    "\n",
    "def model_chat_template(row):\n",
    "    return tokenizer.apply_chat_template([\n",
    "        # {\"role\": \"system\", \"content\": \"\"},\n",
    "        {\"role\": \"user\", \"content\": row[\"instruction\"] + \"\\n\" + row[\"transcript\"]},\n",
    "    ], tokenize=False)\n",
    "\n",
    "df[\"model_input\"] = df.apply(model_chat_template, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "100%|██████████| 51/51 [00:04<00:00, 10.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# use unembedding tokenization form\n",
    "def get_gt_representation(batch_of_strs: list[str], number_of_tokens: int = 128) -> torch.Tensor:\n",
    "    inputs = tokenizer(batch_of_strs, return_tensors=\"pt\", padding=True, truncation=False).to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        return model(**inputs).hidden_states[-1][:, -number_of_tokens:].flatten(1)\n",
    "\n",
    "gt_representations = {\n",
    "    comedian: get_gt_representation(batch.tolist())\n",
    "    for comedian, batch in tqdm(df.groupby(\"comedian\")[\"model_input\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51 [00:00<?, ?it/s]The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\n",
      "100%|██████████| 51/51 [01:49<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_output_representation(batch_of_strs: list[str], number_of_tokens: int = 128) -> torch.Tensor:\n",
    "    inputs = tokenizer(batch_of_strs, return_tensors=\"pt\", padding=True, truncation=False).to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        return model(input_ids=model.generate(**inputs, max_new_tokens=128)).hidden_states[-1][:, -number_of_tokens:].flatten(1)\n",
    "\n",
    "output_representations = {\n",
    "    comedian: get_output_representation(batch.tolist())\n",
    "    for comedian, batch in tqdm(df.groupby(\"comedian\")[\"gt_input\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 294912])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_representations[\"Ali_Wong\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 294912])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_representations[\"Ali_Wong\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 239.06it/s]\n"
     ]
    }
   ],
   "source": [
    "def make_subspace(data: torch.FloatTensor, q: int = 3) -> torch.Tensor:\n",
    "    data = torch.nn.functional.normalize(data, p=2, dim=-1)\n",
    "    data = data - data.mean(0, keepdim=True)\n",
    "    *_, Vh = torch.pca_lowrank(data, q=q)\n",
    "    return Vh\n",
    "\n",
    "scores = {}\n",
    "for comedian in tqdm(gt_representations.keys()):\n",
    "    gt_reference_subspace = make_subspace(gt_representations[comedian].float())\n",
    "    out_reference_subspace = make_subspace(output_representations[comedian].float())\n",
    "\n",
    "    A = gt_reference_subspace.mT @ out_reference_subspace\n",
    "    scores[comedian] = (A.mT @ A).trace() / A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(scores, index=range(len(scores))).to_csv(\"scores.csv\")\n",
    "df = pd.DataFrame(list(scores.items()), columns=['Comedian', 'Score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
