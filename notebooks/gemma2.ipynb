{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemma 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ada/humor/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-9b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-9b-it\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# pipe = pipeline(\"text-generation\", model=\"google/gemma-2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "# ]\n",
    "\n",
    "# pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = pd.read_csv('/home/ada/humor/data/stand_up_dataset/standup_transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranscript\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minstruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m response \u001b[38;5;241m=\u001b[39m generated_text\u001b[38;5;241m.\u001b[39mreplace(prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/transformers/generation/utils.py:1914\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1906\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1907\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1908\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1909\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1911\u001b[0m     )\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m     )\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/transformers/generation/utils.py:2651\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2648\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2651\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2659\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/transformers/models/gemma2/modeling_gemma2.py:1068\u001b[0m, in \u001b[0;36mGemma2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1065\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1068\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1081\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1082\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/transformers/models/gemma2/modeling_gemma2.py:908\u001b[0m, in \u001b[0;36mGemma2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    897\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    898\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    899\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    905\u001b[0m         cache_position,\n\u001b[1;32m    906\u001b[0m     )\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 908\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/transformers/models/gemma2/modeling_gemma2.py:664\u001b[0m, in \u001b[0;36mGemma2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    662\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    663\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_feedforward_layernorm(hidden_states)\n\u001b[0;32m--> 664\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_feedforward_layernorm(hidden_states)\n\u001b[1;32m    666\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/accelerate/hooks.py:161\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 161\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/accelerate/hooks.py:356\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[1;32m    347\u001b[0m         set_module_tensor_to_device(\n\u001b[1;32m    348\u001b[0m             module,\n\u001b[1;32m    349\u001b[0m             name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m             tied_params_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map,\n\u001b[1;32m    354\u001b[0m         )\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m)\u001b[49m, send_to_device(\n\u001b[1;32m    357\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    358\u001b[0m )\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/accelerate/utils/operations.py:177\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhonor_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, Mapping):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(skip_keys, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/accelerate/utils/operations.py:81\u001b[0m, in \u001b[0;36mhonor_type\u001b[0;34m(obj, generator)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(generator))\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/accelerate/utils/operations.py:178\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[0;32m--> 178\u001b[0m         tensor, (\u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tensor)\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, Mapping):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(skip_keys, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/accelerate/utils/operations.py:155\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    153\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# TODO: torch_mlu LongTensor.to(<int num>) has bugs, we will fix this later.\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_tensor(tensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlu\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m [torch\u001b[38;5;241m.\u001b[39mint64]:\n\u001b[1;32m    156\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "for index, row in transcripts.iterrows():\n",
    "    comedian = row['comedian']\n",
    "    transcript = row['transcript'] \n",
    "    \n",
    "    prompt = f\"'''{transcript}'''\\n\\n{instruction}\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=120)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = generated_text.replace(prompt, \"\").strip()\n",
    "    results_dict[comedian] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': '* \"Sold my passport on the street for 300 bucks to get to my prom.\"\\n* \"Weird joke to clap for, but sure.\"\\n* \"My mom actually should’ve been on one of the planes that crashed on 9/11. I think.\"\\n* \"And I do not tolerate racism. That’s ignorance and I hate that.\"\\n* \"Shut up, Mom, that’s racist. Put your money away.\"\\n* \"Most of them are in jail, to be honest.\"\\n* \"‘Cause they’re all',\n",
       " 'Anthony_Jeselnik_2': '* \"And I know my grandma loved it too, because it combined her two favorite things: spending time with her grandchildren, and using the ‘N’ word.”\\n* \"Now I promise you… I promise you… until you’ve heard your grandfather gasp at his own wife’s funeral… …at a Methodist Church in Vicksburg, Mississippi… you are not a real comedian.\"\\n* \"I am a real comedian. I am a pure comedian. I think I’m one of the best comedians of all time.\"\\n\\n\\n**Explanation:**\\n\\nThe humor in this excerpt relies on',\n",
       " 'Ali_Wong': '* \"Don’t ever do that with your mom.\"\\n* \"It was so emotional. We were screaming and fighting and yelling and it all came to a climax when she refused to let go of a Texas Instruments TI-82… manual.\"\\n* \"She don’t even know… where the calculator is.\"\\n* \"It was this calculator that bamboozled my generation. We were all required to buy it when we were in eight grade. It cost like $200. And everybody thought it could graph. It was like the Tesla of my time.\"',\n",
       " 'Ali_Wong_2': '* **\"My mom is 80, going through a full blown mid-life crisis. ‘Cause she knows that she’s got a century more to go.\"**\\n* **\"I’m just kidding. She doesn’t have any black friends.\"**\\n* **\"Life is not Rush Hour, the movie, OK?\"**\\n* **\"Old Chinese ladies, they don’t give a fuck. They got no shame.\"**\\n* **\"They do that ’cause it’s a free activity. For them.\"**\\n* **\"They',\n",
       " 'Chelsea_Peretti': '*  \"It’s like that wedding portraiture, where it’s just like, two assholes back to back in the woods, just like… [laughing shrilly] “To the future!”\"\\n*  \"[giggles shrilly] “Uh-oh, it’s us again.” [trills]\"\\n*  \"She calls him by a word that I really feel is one of the more disgusting words in the English language. She calls him her “hubby,” which, to me is on par with the “N” word. Like let’s…',\n",
       " 'Chelsea_Peretti_2': '* **\"People say I look just like you.\"**\\n* **\"It’s actually to stop them from sweating, because why would you, you know, as a human?\"**\\n* **\"It worked. I did stop sweating out of my armpits, but I started sweating out of my butthole.\"**\\n* **\"Is that a good trade? like, kind of a deal with the devil.\"**\\n* **\"Oh, ho, ho, ho.\"**\\n* **\"She is so fucking hot. Her armpits are bone-fucking-',\n",
       " 'Donald_Glover': '* **\"tears streaming down his face, but he wasn’t crying. He wasn’t crying. Just tears, he was giving me this mean mug\"**\\n* **\"The sweetest thing he was allowed was mints. He was just allowed to have mints.\"**\\n* **\"the vapors from his own mouth made his eyes water\"**\\n* **\"And then like… Just, they would just bleed… It was crazy.\"**\\n* **\"And he goes, “Shut up.” And she goes, “Don’t you talk to me like',\n",
       " 'Donald_Glover_2': '* **\"Yeah, well, “if anybody ever tries to rape me, I’m just gonna shit on ’em.” “Yes, I will. I have no problem.”**\\n* **\"Number one, he’s a rapist. So his tolerance for gross stuff is probably pretty high. It’s probably pretty high.\"**\\n* **\"You can shit on command? Like, you can just… You can just poop whenever you want to? Just be like… Hyah! He’s like, “Oh God, no!”\"**\\n* **\"',\n",
       " 'Hasan_Minhaj': '* \"Are you fucking kidding? Thirteen episodes for this kid?\"\\n* \"Do you know when br0wn kids get slapped? Every br0wn birthday party.\"\\n* \"And usually it’s the kid whose birthday it is, and we stand there and point and laugh. We go, “Ah, Biju got slapped on his birthday!”\"\\n* \"It’s why we become cardiologists and win spelling bees.\"\\n* \"You ever seen an Indian kid win a spelling bee? Incredible! Ice water in the veins.\"\\n* \"That kid won’t',\n",
       " 'Hasan_Minhaj_2': '* \"Getting into Stanford.\"\\n* \"No, you have to live a life worth talking about, which is why I’m making it mandatory for everyone in this class to go to prom.\"\\n* \"All 30 of us? We’re all going to prom? AP Calc? Us? Me, Jehovah’s Witness girl, Korean exchange students, going to the prom? Thirty for 30? All of us?\"\\n* \"Hanson, this is not funny.\"\\n* \"Whatever, it’s not going to happen. He can’t do',\n",
       " 'Iliza_Shlesinger': '* \"Granted, I’m not married yet, so, technically, I’ve only had beginnings of relationships.\"\\n* \"You want him to come in and be, like, “It’s so homey. I’d like to stay forever.” Yes, come closer.\"\\n* \"In your 30s… In your 30s, homeboy knocks on the door, you open it, you’re in combat boots, nothing else, and a garbage can on fire, you’re, like, “Welcome to Fuckdome, Scott.” Ticket',\n",
       " 'Iliza_Shlesinger_2': '* \"You don’t want to wear your daytime clothes, ’cause… ’cause it’s nighttime.\"\\n* \"You don’t want to go, like, super hardcore sexy the first time a guy’s coming over. Just relax.\"\\n* \"You don’t want to wear nipple tassels.\"\\n* \"The blood’s gonna go from here to his dick, he’s gonna impale himself, he’s gonna sue you, and you ain’t got no money.\"\\n* \"It’d be like if you have the worst day,',\n",
       " 'Jim_Gaffigan': '* \"We got nothing for you. And you can’t use our bathroom.”\\n* \"Aw. Look at you try.”\\n* \"The fat pig is trying, the fat pig is trying, I…”\\n* \"Good show.” “You nailed it.” I don’t care. I like to eat! I like to eat.\"\\n* \"Well, you must know your way around the kitchen. I know where the food is.\"\\n* \"Well, you must love to cook. Look, I like to sleep. It doesn’t mean I wanna build a',\n",
       " 'Jim_Gaffigan_2': '* \"I have friends that are mentally ill.\"\\n* \"Didn\\'t suspect a thing. Dog didn’t know it was his birthday. The dog didn’t know it had a birthday.\"\\n* \"Oh, one year equals seven for doggies? Okay. When I see a dog, I’ll do math. That’s not fulfilling some dog need, you know?\"\\n* \"There’s not a dog sitting in a bar right now going, “I’m not three, I’m 21! I can legally drink!”\"\\n*',\n",
       " 'Joe_List': '* \"It’s one doctor. He knows all three body parts.\"\\n* \"“Ear, nose, throat. “Who do ya need?”\"\\n* \"And they all kinda.\"\\n* \"I thought it was called tinnitus, but then I watched a YouTube video, and the doctor in the video, he kept saying “tin-uh-dus.”\"\\n* \"“This guy’s a fake ass fucking retard doctor. It’s pronounced t-ah-n-i-tus.”\"\\n* \"Tomato, to-mah-to. However you',\n",
       " 'Joe_List_2': '* **\"You feel better than everybody behind you, don’t you?\"**\\n* **\"What a fucking idiot back there. Embarrassing, loser.\"**\\n* **\"The whole flight he’s like. [yawns] For like five hours. [yawns] I wanted him to die, I swear to God.\"**\\n* **\"First of all, you don’t need to make a noise when you yawn. That’s a decision, he’s deciding to do that.\"**\\n* **\"People who yawn out loud, they want',\n",
       " 'John_Mulaney': '* \"We made these big piles of clothes, we put the piles into these big boxes, then we put the boxes into the back of my car, and then they stayed there for four months.\"\\n* \"And then one day my wife said, “Hey, you took that stuff to Goodwill, right?” And I said, “Of course I did! On an unrelated note, I’m going to walk out the front door right now.”\"\\n* \"It was charitable, but it was also fast and violent, because I was throwing boxes at people.\"\\n* \"The',\n",
       " 'John_Mulaney_2': '* \"Go ahead and laugh. His name is ridiculous. That was his name. It was JJ Bittenbinder.\"\\n* \"Very sorry, Radio City, did that make you uncomfortable? Well, guess what? You’re adults and he’s not even here. So try being seven years old and you’re sitting five feet away from him.\"\\n* \"He’s still got blood on his shoes. And he’s looking at you in the eye to tell you for the first time in your very young life that some adults find you incredibly attractive. [audience laughing',\n",
       " 'Jimmy_Yang': '* **\"Asian people, we don’t need Tinder anymore. We just go to BTS concerts. That’s how we do that parking lot pimping.\"**\\n* **\"I’ve been dating a lot of tall girls lately, because it makes me look successful.\"**\\n* **\"But some of them like to wear heels. That’s just disrespect. Like, you’re already five inches taller than me. Why the fuck are you wearing heels? She’s like, it makes my ass look better. I’m like, your ass is at my',\n",
       " 'Jimmy_Yang_2': '* **\"Like, it’s really hard for me to watch TV with my dad, because he’s trying to make me explain everything to him.\"**\\n* **\"First of all, old Asian people, they don’t watch TV. They judge the TV.\"**\\n* **\"He’s just sitting there, arms folded, judging the TV like–\"**\\n* **\"He’s made some random noises around the house. Now whenever he sneezes, it’s never just a sneeze. It’s like a whole tsunami of sound waves that',\n",
       " 'Louis_CK': '* \"He was?\"\\n* \"Yeah. Jesus was Jewish.\"\\n* \"I don’t think so.\"\\n* \"Dude, Jesus couldn’t be Jewish. Think about it.\"\\n* \"You fucking think about it, you idiot. What d– What was he then? You’re… What, was he Presbyterian? What was he? Catholic?\"\\n* \"Okay, Jesus was Catholic and he had a gold chain with a cross. And when they nailed him up, he was like, “Oh, that’s why we have those!” “That finally',\n",
       " 'Louis_CK_2': '* \"They’re in our lives and they know nothing about what’s happening.\"\\n* \"You ever been having, like, a dramatic moment in your family, like, you’re in the living room telling the kids that grandma died, and everybody’s crying, and the dog’s sitting there like…“I know you! Ha!” They’re so stupid!\"\\n* \"Incredibly stupid animals. They don’t even know their own lives, they don’t even — they can’t even handle their own lives mentally.\"\\n* \"And then',\n",
       " 'Nate_Bargatze': '* **\"I’ve never thought about an author a day in my life, so… That never occurred to me.\"**\\n* **\"I love when kids cry, it’s just innocent. I love how innocent it is. They cry over a tag in their shirt. I mean, they bawl. They don’t like… It feels weird.\"**\\n* **\"You could be like, “Is your house on fire?” I’ve never seen someone cry this much. It’s over nothing.\"**\\n* **\"She wants to be a YouTuber',\n",
       " 'Nate_Bargatze_2': '* **\"They throw some stuff in, you’re like, “Oh, all right. All right.” It’s, uh… “Okay, learning it earlier than we used to, huh?” I don’t even know if that’s true, but…\"** -  This line uses a sarcastic tone to express the speaker\\'s confusion and mild annoyance at the increasing complexity of homework.\\n* **\"Common Core math. That’s fun. It’s a new math they invented, no heads up. Just give it to parents that never learned it.\"**',\n",
       " 'Nate_Bargatze_TK': '* \"Uh… It goes clown, then magic. There’s two steps. You can take them in either order.\"\\n* \"I thought everybody’s dad was a clown.\"\\n* \"The Easter Bunny was in the passenger seat.\"\\n* \"The Easter Bunny head didn’t fit in the car. Like, he couldn’t sit normal, so his head was bent to the side.\"\\n* \"And I remember he had his seat belt on, and he’s just like…\"\\n* \"I like to think about all the other people that saw that.',\n",
       " 'Nate_Bargatze_TK_2': '* \"Tuesday’s getting married, rehearsal’s Friday, wedding’s Saturday.”\\n* \"We gotta be there Monday for this wedding? How long is this wedding? It’s a week?”\\n* \"I’m wildly overdressed. I look like I work there.\"\\n* \"Everybody else just has a football or basketball jersey on.\"\\n* \"He has his tuxedo jacket, pants, cummerbund, bowtie. No shirt.\"\\n* \"They forgot his shirt, and instead of waiting to go get it, he was like, “Let’s',\n",
       " 'Russell_Peters': '* \"What do you mean what else is wrong with me?\"\\n* \"that’s really fucking racist, but since you asked, I have acid reflux.\"\\n* \"Because there is no way you can be Indian and not have fucking acid reflux.\"\\n* \"It’s inevitable. There’s no way you can consume the food that we eat with that much spice, and that much oil, and that much butter, and not just have it burn a hole in your– as my dad would say– your esophagus.\"\\n* \"Dad, I want to assure you I',\n",
       " 'Russell_Peters_2': '* \"If I have twin girls– because you’ve got to have fun with the names. If I have twin girls, these are going to be my daughters, it’s going to be Kate and Duplicate. These are my boys, it’s Pete and Repeat.\"\\n* \"If I had twins with a black girl, this is Tyrone and Tyclone.\"\\n* \"Identical twins, that’s like bragging rights for you, you know I mean. That’s your way of going, look. Look at how good my balls are. Look, look.\"',\n",
       " 'Sam_Morril': '* \"That is male privilege right there, isn’t it? I just told a room full of people I got roofied. I did not see one concerned face in here. Everyone in here is like I assume things worked out for you, and they did. Still weird, though.\"\\n* \"And I was like, I’ll drink it. And he gave me this hateful look, and I thought, why is this guy so mad at me? And then I chugged it, and I woke up the next morning, and I was like oh. That guy’s',\n",
       " 'Sam_Morril_2': '* \"It’s weird that they can do anti-smoking ads, but you can’t do pro-cigarette commercials. Isn’t that weird? They don’t give ’em a rebuttal.\"\\n* \"A hot girl walks up to a guy in the bar and asks to bum a cigarette, and he goes, oh, I don’t smoke. So then she goes outside and bums them from another guy, and they go home together and they fuck and that’s the whole commercial. There at the end, it just says, “Wouldn’t kill you',\n",
       " 'Trevor_Noah': '* \"You know how I know this? You know how I’ve learned? Because I’ve learned how to use the Russian accent for myself.\"\\n* \"I’ll share this with you, I don’t mind. I, uh– I’m not particularly comfortable in the house at night by myself. What I’m trying to say is I’m afraid of the dark.\"\\n* \"But what happens is, I’ll be sleeping. And in the middle of the night, I’ll be woken up by the need to pee. And whenever that',\n",
       " 'Trevor_Noah_2': '* \"And a Kit Kat, please.\"\\n* \"Who the hell is this?!\"\\n* \"I’m not telling you.\"\\n* \"Ah, knock, knock.\"\\n* \"Let him in. Let him in!\"\\n* \"No. No, no. You must say, ‘Who’s there?\\'”\\n* \"He is so right. We’ve always got to ask, ‘Who’s there?’ Who’s here? Who are we?’ Oh, my God!\"\\n\\n\\n**Humorous Lines and Punchlines:**\\n\\n* **\"And a',\n",
       " 'Tom_Segura': '* **\"The most terrifying housing situation that exists. Where other trailer people are like, “Get the fuck out of here.” Kick ’em out.\"**\\n* **\"You don’t fuckin’ have it? Isn’t that your sole responsibility?”**\\n* **\"Let’s go get it.” He goes, “I’ll go get it. You stay here and watch my place.” And I was like… “Okay.”**\\n* **\"That’s what’s up.” -Like, yeah, man. Pow.**\\n* **\"But',\n",
       " 'Tom_Segura_2': '* \"I got such a warm rush through my body. It felt like the inside of my body hugged the outside of my body, you know?\"\\n* \"I think it’s a taste of power. Like most of us, we have no power in our everyday lives.\"\\n* \"You are lord of the elevator shaft. You get to decide, like a king with his drawbridge.\"\\n* \"And you can watch people walk up and be like, “Mm-mm.” -And you hit that.\"\\n* \"Sometimes, a second later it opens, and you'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"The following is a stand-up comedy transcript. When performed in front of a live audience, which jokes do you think made the audience laugh?  List of quotes:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "for index, row in transcripts.iterrows():\n",
    "    comedian = row['comedian']\n",
    "    transcript = row['transcript'] \n",
    "    \n",
    "    prompt = f\"'''{transcript}'''\\n\\n{instruction}\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=120)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = generated_text.replace(prompt, \"\").strip()\n",
    "    results_dict[comedian] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': '* \"So poor I remember, just so I could go to my senior prom, just so I could go to my senior prom, I had to sell my U.S. passport on the street. Sold my passport on the street for 300 bucks to get to go to my prom.\"\\n* \"Of course this was before 9/11 so… my bad, everybody. Weird joke to clap for, but sure.\"\\n* \"My mom actually should’ve been on one of the planes that crashed on 9/11. I think.\"\\n*',\n",
       " 'Anthony_Jeselnik_2': '* \"I asked a friend for advice. Was like, “I’ve never talked to a group of people without getting paid a lot of money. How should I handle this?”\"\\n* \"Anthony, just go up there and tell a story. Find one moment about you and your grandma you can share with everybody. And don’t tell a joke. Try not to.”\"\\n* \"You know what my favorite memory was? When I was like four years old, before I learned to read, Grandma would curl up with me on the couch, she had this Southern accent',\n",
       " 'Ali_Wong': '* \"Don’t ever do that with your mom.\"\\n* \"It was like the worst experience of my life.\"\\n* \"We were screaming and fighting and yelling and it all came to a climax when she refused to let go of a Texas Instruments TI-82… manual.\"\\n* \"She don’t even know… where the calculator is.\"\\n* \"It was this calculator that bamboozled my generation.\"\\n* \"We were all required to buy it when we were in eight grade.\"\\n* \"It cost like $200. And everybody thought',\n",
       " 'Ali_Wong_2': '* \"My mom is 80, going through a full blown mid-life crisis. ‘Cause she knows that she’s got a century more to go.\"\\n* \"All of her white friends, dead. Her Mexican friends, dead. Black friends, dead. I’m just kidding. She doesn’t have any black friends.\"\\n* \"Life is not Rush Hour, the movie, OK?\"\\n* \"Old Chinese ladies, they don’t give a fuck. They got no shame.\"\\n* \"They do that ’cause it’s a free activity',\n",
       " 'Chelsea_Peretti': '*  \"It’s like that wedding portraiture, where it’s just like, two assholes back to back in the woods, just like… [laughing shrilly] “To the future!”\\n*  \"Every photo, they were just like… [giggles shrilly] “Uh-oh, it’s us again.” [trills]\\n*  \"She calls him by a word that I really feel is one of the more disgusting words in the English language. She calls him her “hubby,” which, to me is on par with the “N',\n",
       " 'Chelsea_Peretti_2': '* \"People say I look just like you.\"\\n* \"It worked. I did stop sweating out of my armpits, but I started sweating out of my butthole.\"\\n* \"Oh, ho, ho, ho.\"\\n* \"She is so fucking hot. Her armpits are bone-fucking-dry… just like I always dreamed of.\"\\n* \"Whoa, whoa, whoa!\"\\n* \"I’m so drawn to you, but I can’t get near you! This is a whole new kind of juicy booty.\"\\n* \"Just stop making such',\n",
       " 'Donald_Glover': '* \"tears streaming down his face, tears streaming down his face, but he wasn’t crying. He wasn’t crying. Just tears, he was giving me this mean mug, he was like…\"\\n* \"What the fuck is wrong with this kid? What’s going on with this kid?\"\\n* \"The sweetest thing he was allowed was mints. He would… The sweetest thing he was allowed was mints.\"\\n* \"So his breath was so fresh… the vapors from his own mouth made his eyes water.\"\\n* \"Like, he’d be',\n",
       " 'Donald_Glover_2': '* \"Yeah, well, “if anybody ever tries to rape me, I’m just gonna shit on ’em.” “Yes, I will. I have no problem.”\"\\n* \"Number one, he’s a rapist. So his tolerance for gross stuff is probably pretty high. It’s probably pretty high.\"\\n* \"You can shit on command? Like, you can just… You can just poop whenever you want to? Just be like… Hyah! He’s like, “Oh God, no!” Like…\"\\n* \"You got more superpowers than',\n",
       " 'Hasan_Minhaj': '* \"Are you fucking kidding? Thirteen episodes for this kid?\"\\n* \"Do you know when br0wn kids get slapped? Every br0wn birthday party.\"\\n* \"And usually it’s the kid whose birthday it is, and we stand there and point and laugh. We go, “Ah, Biju got slapped on his birthday!”\"\\n* \"It’s why we become cardiologists and win spelling bees.\"\\n* \"You ever seen an Indian kid win a spelling bee? Incredible! Ice water in the veins.\"\\n* \"That kid won’t',\n",
       " 'Hasan_Minhaj_2': '* “I know, getting into Stanford.”\\n* “No, you have to live a life worth talking about, which is why I’m making it mandatory for everyone in this class to go to prom.”\\n* “All 30 of us? We’re all going to prom? AP Calc? Us? Me, Jehovah’s Witness girl, Korean exchange students, going to the prom? Thirty for 30? All of us?”\\n* “Hanson, this is not funny.”\\n* “Whatever, it’s not going to happen. He can',\n",
       " 'Iliza_Shlesinger': '* \"Granted, I’m not married yet, so, technically, I’ve only had beginnings of relationships.\"\\n* \"You’re both on your best behavior, it’s still electric, you’re not totally sure about the history of mental illness in each family. It’s fun.\"\\n* \"You want him to come in and be, like, “It’s so homey. I’d like to stay forever.” Yes, come closer. Like, that’s what you want.\"\\n* \"In your 30s… In your',\n",
       " 'Iliza_Shlesinger_2': '* \"You don’t want to wear… what you wore during the day. Don’t want work clothes. You don’t want to wear your daytime clothes, ’cause… ’cause it’s nighttime. What if that was the end of my show? I hit my head.\"\\n* \"You don’t want to wear your civilian clothes, okay. ‘Cause you had a whole day. Maybe you sweat in them, they’re gross.\"\\n* \"However, at the other end of the sartorial spectrum, you don’t want to go, like',\n",
       " 'Jim_Gaffigan': '* \"We got nothing for you. And you can’t use our bathroom.”\\n* \"Aw. Look at you try.”\\n* \"The fat pig is trying, the fat pig is trying, I…”\\n* \"Good show.” “You nailed it.” I don’t care. I like to eat! I like to eat.\\n* \"Well, you must know your way around the kitchen. I know where the food is.\\n* \"Well, you must love to cook. Look, I like to sleep. It doesn’t mean I wanna build a',\n",
       " 'Jim_Gaffigan_2': '* \"I have friends that are mentally ill.\"\\n* \"Didn\\'t suspect a thing. Dog didn\\'t know it was his birthday. The dog didn\\'t know it had a birthday.\"\\n* \"Oh, one year equals seven for doggies? Okay. When I see a dog, I’ll do math. That’s not fulfilling some dog need, you know?\"\\n* \"There’s not a dog sitting in a bar right now going, “I’m not three, I’m 21! I can legally drink!” That’s',\n",
       " 'Joe_List': '* \"It’s one doctor. He knows all three body parts.\"\\n* \"Ear, nose, throat. “Who do ya need?” And they all kinda.\"\\n* \"I have an ear issue called, , tinnitus, or tin-uh-dus.\"\\n* \"You got it? Yeah, it’s frustrating. It’s when you’re ears ring, or buzz all the time. I don’t know how you say it.\"\\n* \"This guy’s a fake ass fucking retard doctor. It’s pronounced t-ah-n-',\n",
       " 'Joe_List_2': '* \"You feel better than everybody behind you, don’t you?\"\\n* \"Embarrassing, loser.\"\\n* \"The whole flight he’s like. [yawns] For like five hours. [yawns] I wanted him to die, I swear to God.\"\\n* \"That’s a decision, he’s deciding to do that.\"\\n* \"People who yawn out loud, they want attention. That’s why they’re doing it.\"\\n* \"Neat.\"\\n* \"Don’t make me ask for it.\"\\n* \"That',\n",
       " 'John_Mulaney': '* \"We made these big piles of clothes, we put the piles into these big boxes, then we put the boxes into the back of my car, and then they stayed there for four months.\"\\n* \"And then one day my wife said, “Hey, you took that stuff to Goodwill, right?” And I said, “Of course I did! On an unrelated note, I’m going to walk out the front door right now.”\"\\n* \"It was charitable, but it was also fast and violent, because I was throwing boxes at people.\"\\n* \"The',\n",
       " 'John_Mulaney_2': '* \"Go ahead and laugh. His name is ridiculous. That was his name. It was JJ Bittenbinder.\"\\n* \"Very sorry, Radio City, did that make you uncomfortable? Well, guess what? You’re adults and he’s not even here. So try being seven years old and you’re sitting five feet away from him.\"\\n* \"He’s still got blood on his shoes. And he’s looking at you in the eye to tell you for the first time in your very young life that some adults find you incredibly attractive. [audience laughing',\n",
       " 'Jimmy_Yang': '* \"Asian people, we don’t need Tinder anymore. We just go to BTS concerts. That’s how we do that parking lot pimping.\"\\n* \"I’ve been dating a lot of tall girls lately, because it makes me look successful.\"\\n* \"No, no. I think tall women are beautiful. But some of them like to wear heels. That’s just disrespect. Like, you’re already five inches taller than me. Why the fuck are you wearing heels? She’s like, it makes my ass look better. I’m like',\n",
       " 'Jimmy_Yang_2': '* \"But my parents, they’re like negative 9 generation, because they’re so frickin’ Chinese.\"\\n* \"First of all, old Asian people, they don’t watch TV. They judge the TV.\"\\n* \"He’s just sitting there, arms folded, judging the TV like–\"\\n* \"He’s made some random noises around the house. Now whenever he sneezes, it’s never just a sneeze. It’s like a whole tsunami of sound waves that comes after.\"\\n* \"It’s just like, ach',\n",
       " 'Louis_CK': '1. \"He was?\"\\n2. \"Yeah. Jesus was Jewish.\"\\n3. \"I don’t think so.\"\\n4. \"Dude, Jesus couldn’t be Jewish. Think about it.\"\\n5. \"You fucking think about it, you idiot.\"\\n6. \"What d– What was he then? You’re… What, was he Presbyterian? What was he? Catholic?\"\\n7. \"Jesus was Catholic and he had a gold chain with a cross.\"\\n8. \"And when they nailed him up, he was like, “Oh',\n",
       " 'Louis_CK_2': '* \"They’re in our lives and they know nothing about what’s happening.\"\\n* \"You ever been having, like, a dramatic moment in your family, like, you’re in the living room telling the kids that grandma died, and everybody’s crying, and the dog’s sitting there like…“I know you! Ha!” They’re so stupid!\"\\n* \"Incredibly stupid animals. They don’t even know their own lives, they don’t even — they can’t even handle their own lives mentally.\"\\n* \"You ever',\n",
       " 'Nate_Bargatze': '* \"Did you name her after Harper Lee, the author of To Kill a Mockingbird?\" And, you know, I’ve never thought about an author a day in my life, so… That never occurred to me. I mean, my middle name is Lee, and it just never crossed my mind.\"\\n* \"I love having a kid. We… I love\\xa0when kids cry, it’s just innocent. I love how innocent it is. They cry over a tag in their shirt. I mean, they bawl. They don’t like… It feels weird',\n",
       " 'Nate_Bargatze_2': '* \"First and second grade was awesome. Third grade, you’re like, “Okay.” They throw some stuff in, you’re like, “Oh, all right. All right.” It’s, uh… “Okay, learning it earlier than we used to, huh?” I don’t even know if that’s true, but…\"\\n* \"She brought home Common Core math. That’s fun. It’s a new math they invented, no heads up. Just give it to parents that never learned it.\"\\n* \"It’s just a',\n",
       " 'Nate_Bargatze_TK': '* \"Uh… It goes clown, then magic. There’s two steps. You can take them in either order.\"\\n* \"I was born, he was a clown. It was never weird to me. I thought everybody’s dad was a clown.\"\\n* \"The Easter Bunny was in the passenger seat.\"\\n* \"The Easter Bunny head didn’t fit in the car. Like, he couldn’t sit normal, so his head was bent to the side.\"\\n* \"And I remember he had his seat belt on, and he’s just like…\"',\n",
       " 'Nate_Bargatze_TK_2': '* \"Tuesday’s getting married, rehearsal’s Friday, wedding’s Saturday.”\\n* \"We gotta be there Monday for this wedding? How long is this wedding? It’s a week?”\\n* \"I’m wildly overdressed. I look like I work there.\"\\n* \"Everybody else just has a football or basketball jersey on.\"\\n* \"They forgot his shirt, and instead of waiting to go get it, he was like, “Let’s do it without it.”\"\\n* \"Like, that’s… And he doesn’t have',\n",
       " 'Russell_Peters': '* \"I go, what do you mean what else is wrong with me? He goes, look, you’re a 48-year-old Indian man.\"\\n* \"First of all, you’re lying to me right now. Because there is no way you can be Indian and not have fucking acid reflux.\"\\n* \"It’s inevitable. There’s no way you can consume the food that we eat with that much spice, and that much oil, and that much butter, and not just have it burn a hole in your– as my dad would say',\n",
       " 'Russell_Peters_2': '* \"Identical twins are the only people that should be twins.\"\\n* \"If I have twin girls, these are going to be my daughters, it’s going to be Kate and Duplicate.\"\\n* \"These are my boys, it’s Pete and Repeat.\"\\n* \"If I had twins with a black girl, this is Tyrone and Tyclone.\"\\n* \"Identical twins, that’s like bragging rights for you, you know I mean.\"\\n* \"That’s your way of going, look. Look at how good my balls are.\"\\n*',\n",
       " 'Sam_Morril': '* \"That is male privilege right there, isn’t it? I just told a room full of people I got roofied. I did not see one concerned face in here. Everyone in here is like I assume things worked out for you, and they did. Still weird, though.\"\\n* \"And I chugged it, and I woke up the next morning, and I was like oh. That guy’s a sexual predator.\"\\n* \"And my friend said you ruined his night. And I was like, that’s not how I want to think about it,',\n",
       " 'Sam_Morril_2': '* \"It’s weird that they can do anti-smoking ads, but you can’t do pro-cigarette commercials. Isn’t that weird? They don’t give ’em a rebuttal.\"\\n* \"A hot girl walks up to a guy in the bar and asks to bum a cigarette, and he goes, oh, I don’t smoke. So then she goes outside and bums them from another guy, and they go home together and they fuck and that’s the whole commercial. There at the end, it just says, “Wouldn’t kill you',\n",
       " 'Trevor_Noah': '* \"You don’t mess with the Russians. Most frightening people in the world. You know how I know this? You know how I’ve learned? Because I’ve learned how to use the Russian accent for myself.\"\\n* \"I’m not particularly comfortable in the house at night by myself. What I’m trying to say is I’m afraid of the dark.\"\\n* \"I’ll be sleeping. And in the middle of the night, I’ll be woken up by the need to pee. And whenever that happens, I’m always faced',\n",
       " 'Trevor_Noah_2': '* \"You can’t do normal things with that voice. You are destined for greatness. You can’t be running in the streets: “And a Kit Kat, please.” No. No.\"\\n* \"It just doesn’t work. I remember when Nelson Mandela was still alive, and he would tell jokes at press conferences and events, and no one would laugh. Because everyone thought a man who had been in jail for 27 years couldn’t make a joke. And yet, he still did. He still kept what was him.\"\\n* \"He would tell',\n",
       " 'Tom_Segura': '* \"The most terrifying housing situation that exists. Where other trailer people are like, “Get the fuck out of here.” Kick ’em out.\"\\n* \"I was like, “Oh, shit. Yeah.” “We could go do that.” I was like, “All right. Cool.” And he goes, “We just need to go get it.” I was like, “You don’t fuckin’ have it? Isn’t that your sole responsibility?”\"\\n* \"I tried to play cool, “Let’s go get it.” He goes, “I',\n",
       " 'Tom_Segura_2': '* \"I got such a warm rush through my body. It felt like the inside of my body hugged the outside of my body, you know?\"\\n* \"I think it’s a taste of power. Like most of us, we have no power in our everyday lives.\"\\n* \"You are lord of the elevator shaft. You get to decide, like a king with his drawbridge.\"\\n* \"And you can watch people walk up and be like, “Mm-mm.” -And you hit that.\"\\n* \"Sometimes, a second later it opens, and you'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"The following is a stand-up comedy transcript. What are the funniest punchlines from the transcript. List of quotes:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "for index, row in transcripts.iterrows():\n",
    "    comedian = row['comedian']\n",
    "    transcript = row['transcript'] \n",
    "    \n",
    "    prompt = f\"'''{transcript}'''\\n\\n{instruction}\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=120)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = generated_text.replace(prompt, \"\").strip()\n",
    "    results_dict[comedian] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': '* \"Sold my passport on the street for 300 bucks to get to my prom.\"\\n* \"Weird joke to clap for, but sure.\"\\n* \"My mom actually should’ve been on one of the planes that crashed on 9/11. I think.\"\\n* \"And I do not tolerate racism. That’s ignorance and I hate that.\"\\n* \"Shut up, Mom, that’s racist. Put your money away.\"\\n* \"Most of them are in jail, to be honest.\"\\n* \"‘Cause they’re all',\n",
       " 'Anthony_Jeselnik_2': '* \"And I know my grandma loved it too, because it combined her two favorite things: spending time with her grandchildren, and using the ‘N’ word.”\\n* \"Now I promise you… I promise you… until you’ve heard your grandfather gasp at his own wife’s funeral… …at a Methodist Church in Vicksburg, Mississippi… you are not a real comedian.\"\\n* \"I am a real comedian. I am a pure comedian. I think I’m one of the best comedians of all time.\"\\n\\n**Analysis:**\\n\\nThe funniest punchlines are subjective,',\n",
       " 'Ali_Wong': '* \"It was like the worst experience of my life. It was so emotional.\"\\n* \"She don’t even know… where the calculator is.\"\\n* \"It was this calculator that bamboozled my generation. We were all required to buy it when we were in eight grade. It cost like $200. And everybody thought it was like this Judy Jetson’s laptop from the future.\"\\n* \"All because what? It could graph.\"\\n* \"And my mom got so emotional about the manual and she was like, “You never know when you',\n",
       " 'Ali_Wong_2': '* \"Life is not Rush Hour, the movie, OK?\"\\n* \"Old Chinese ladies, they don’t give a fuck. They got no shame.\"\\n* \"They’re like, “I’m just gonna recycle… go bald… go to the park, do this shit.”\"\\n* \"They do that ’cause it’s a free activity. For them.\"\\n* \"They do it in their– their big-ass V. Stiviano visor, their Darth Vader-Tomb Raider- Boba Fett helmet.\"\\n* \"They wear that to protect themselves',\n",
       " 'Chelsea_Peretti': '*  \"It’s like that wedding portraiture, where it’s just like, two assholes back to back in the woods, just like… [laughing shrilly] “To the future!”\\n*  \"Every photo, they were just like… [giggles shrilly] “Uh-oh, it’s us again.” [trills]\\n*  \"She calls him by a word that I really feel is one of the more disgusting words in the English language. She calls him her “hubby,” which, to me is on par with the “N',\n",
       " 'Chelsea_Peretti_2': '* \"She’ll be like, “No!”\\n* \"It worked. I did stop sweating out of my armpits, but I started sweating out of my butthole.”\\n* \"Is that a good trade? like, kind of a deal with the devil.\"\\n* \"She is so fucking hot. Her armpits are bone-fucking-dry… just like I always dreamed of.”\\n* \"Whoa, whoa, whoa!” That’s him slipping on her butt sweat.\\n* \"I’m so drawn to you, but I can’t get near',\n",
       " 'Donald_Glover': '* \"He wasn’t crying. Just tears, he was giving me this mean mug, he was like…\"\\n* \"So he would steal mints by the handful. So his breath was so fresh… the vapors from his own mouth made his eyes water.\"\\n* \"And he goes, “Shut up.” And she goes, “Don’t you talk to me like that, I am a grown-up, you will respect me.” And he goes, “Suck my d!ck!”\"\\n* \"And she goes… I shit you not… The lady goes',\n",
       " 'Donald_Glover_2': '* \"his tolerance for gross stuff is probably pretty high. It’s probably pretty high.\"\\n* \"You can shit on command? Like, you can just… You can just poop whenever you want to?\"\\n* \"You got more superpowers than Shaft if you can poop whenever you want.\"\\n* \"Blow my head off.”\\n* \"Me and my butt are, like, always on the third date, I feel like.\"\\n* \"I’m always like, come on, let’s… hurry up, let’s do this. And my butt’s',\n",
       " 'Hasan_Minhaj': '* \"Are you fucking kidding? Thirteen episodes for this kid?\"\\n* \"And usually it’s the kid whose birthday it is, and we stand there and point and laugh. We go, “Ah, Biju got slapped on his birthday!”\"\\n* \"Slapping is important. It elevates your game.\"\\n* \"You ever seen an Indian kid win a spelling bee? Incredible! Ice water in the veins. That kid won’t choke on camera. He’s been slapped on camera.\"\\n* \"Look at that face. Nothing. Nothing! He’',\n",
       " 'Hasan_Minhaj_2': '* \"Getting into Stanford.\"\\n* \"You have to live a life worth talking about, which is why I’m making it mandatory for everyone in this class to go to prom.\"\\n* \"All 30 of us? We’re all going to prom? AP Calc? Us? Me, Jehovah’s Witness girl, Korean exchange students, going to the prom? Thirty for 30? All of us?\"\\n* \"Hanson, this is not funny.\"\\n* \"Whatever, it’s not going to happen. He can’t do this.\"',\n",
       " 'Iliza_Shlesinger': '* \"It’s so homey. I’d like to stay forever.”\\n* \"Welcome to Fuckdome, Scott.”\\n* \"Should I buy a rug or eat dinner? I don’t know.\"\\n\\n\\nThe funniest punchlines are:\\n\\n* **\"Welcome to Fuckdome, Scott.”**  This line is funny because of the unexpected contrast. The speaker sets up a scenario of a typical first date, then abruptly shifts to a chaotic and humorous image of a \"Fuckdome.\" \\n* **\"Should I buy a rug or eat dinner? I don’',\n",
       " 'Iliza_Shlesinger_2': '* \"You don’t want to wear nipple tassels.\"\\n* \"No means no. Kindergarteners get it. I don’t know why we forget that as adult males, but… no means no.\"\\n* \"He’ll be, like, “Oh, my god!” The blood’s gonna go from here to his dick, he’s gonna impale himself, he’s gonna sue you, and you ain’t got no money.\"\\n* \"You know, girls, it’d be like if you have the worst day, you came home to',\n",
       " 'Jim_Gaffigan': '* \"We got nothing for you. And you can’t use our bathroom.\"\\n* \"Aw. Look at you try.\"\\n* \"The fat pig is trying, the fat pig is trying, I…\"\\n* \"Good show.” “You nailed it.” I don’t care. I like to eat! I like to eat.\"\\n* \"You know, when you like to eat, what’s weird is people assume you enjoy cooking.\"\\n* \"Well, you must know your way around the kitchen. I know where the food is.\"\\n* \"Well',\n",
       " 'Jim_Gaffigan_2': '* \"Didn\\'t suspect a thing. Dog didn\\'t know it was his birthday. The dog didn\\'t know it had a birthday.\"\\n* \"Oh, one year equals seven for doggies? Okay. When I see a dog, I’ll do math. That’s not fulfilling some dog need, you know?\"\\n* \"There’s not a dog sitting in a bar right now going, “I’m not three, I’m 21! I can legally drink!” That’s not how dogs keep track of time.\"\\n* \"',\n",
       " 'Joe_List': '* \"Ear, nose, throat. “Who do ya need?”\\n* \"Tomato, to-mah-to. However you say it.\"\\n* \"If you have it, don’t go to the doctor, they don’t do shit.\"\\n* \"My hearing is great. “I hear everything, plus ringing, so. “I kind of have superpower hearing, if you think about it.\"\\n\\n\\nThe funniest punchlines are:\\n\\n1. **\"Ear, nose, throat. “Who do ya need?”**  This line is funny because it sets up',\n",
       " 'Joe_List_2': '* \"I wanted him to die, I swear to God.\"\\n* \"Don’t fall for it, it’s a trap.\"\\n* \"Neat.\"\\n* \"I’m cool.\"\\n* \"I don’t think we need to rock this hard.\"\\n* \"Also it’s a little unnerving to be boarding a flight. And hear, “You’re gonna die!”\"\\n\\n**My picks for the funniest punchlines:**\\n\\n1. **\"I wanted him to die, I swear to God.\"**  This is a classic over-',\n",
       " 'John_Mulaney': '* \"And then one day my wife said, “Hey, you took that stuff to Goodwill, right?” And I said, “Of course I did! On an unrelated note, I’m going to walk out the front door right now.”\"\\n* \"It was charitable, but it was also fast and violent, because I was throwing boxes at people.\"\\n* \"The boxes were so heavy I couldn’t even say what was in them. I was like, “This one’s shirts. I got a bunch of shirts! Take ’em away!”\"\\n*',\n",
       " 'John_Mulaney_2': '* \"His name is ridiculous. That was his name. It was JJ Bittenbinder.\"\\n* \"Very sorry, Radio City, did that make you uncomfortable? Well, guess what? You’re adults and he’s not even here.\"\\n* \"He’s still got blood on his shoes. And he’s looking at you in the eye to tell you for the first time in your very young life that some adults find you incredibly attractive. [audience laughing] And they may just have to kill you over it.\"\\n* \"He looked like he should be the',\n",
       " 'Jimmy_Yang': '* \"We just go to BTS concerts. That’s how we do that parking lot pimping.\"\\n* \"I look like a child, and you look like a child molester.\"\\n* \"I just go to concerts to smell other people’s armpits.\"\\n* \"She was having the time of her life, doing whatever tall people do at concerts, you know, jumping around, obstructing other people’s views, seeing everything.\"\\n* \"I was frustrated. I had enough. So I just looked up at her, I was like, hey! Pick me',\n",
       " 'Jimmy_Yang_2': '* \"Like, it’s really hard for me to watch TV with my dad, because he’s trying to make me explain everything to him.\"\\n* \"First of all, old Asian people, they don’t watch TV. They judge the TV.\"\\n* \"He’s just sitting there, arms folded, judging the TV like–\"\\n* \"He’s made some random noises around the house. Now whenever he sneezes, it’s never just a sneeze. It’s like a whole tsunami of sound waves that comes after.\"\\n* \"It',\n",
       " 'Louis_CK': '* \"Doesn\\'t matter where you think.\"\\n* \"You fucking think about it, you idiot.\"\\n* \"What was he then? You’re… What, was he Presbyterian? What was he?\"\\n* \"Jesus was Catholic and he had a gold chain with a cross.\"\\n* \"And when they nailed him up, he was like, “Oh, that’s why we have those!” \"That finally makes sense. I didn’t even know. Oh, fuck, that’s me! I’m the little guy on it!”\"\\n\\n**',\n",
       " 'Louis_CK_2': '* \"They’re so stupid! Incredibly stupid animals.\"\\n* \"They don’t even know their own lives, they don’t even — they can’t even handle their own lives mentally.\"\\n* \"I didn’t see what happened. I’m sorry, I… I don’t know anything now. Please help.”\\n* \"There it is, right there. It’s right there.”\\n* \"And the dog just looks at your finger ’cause there’s just no way he’s gonna get this concept that there’s an',\n",
       " 'Nate_Bargatze': '* \"It feels weird. And then, you could be like, “Is your house on fire?” I’ve never seen someone cry this much. It’s over nothing.\"\\n* \"She just sits there on her iPad. She wants to be a YouTuber, which, as a comedian, makes me furious.\"\\n* \"It’s not on YouTube. Me and her mom are the only subscribers.\"\\n* \"Like, that’s what’s crazy. It’s not like a show. I’d be fine if she watched a show. She watches just',\n",
       " 'Nate_Bargatze_2': '* \"They throw some stuff in, you’re like, “Oh, all right. All right.” It’s, uh… “Okay, learning it earlier than we used to, huh?” I don’t even know if that’s true, but…\"\\n* \"It’s just a whole new… I mean, it’s unbelievable. They bring it home, you gotta watch a 40-minute YouTube video on Common Core math. I don’t even understand it.\"\\n* \"You… You just want to keep breaking the problem down. You',\n",
       " 'Nate_Bargatze_TK': '* \"It goes clown, then magic. There’s two steps. You can take them in either order.\"\\n* \"I thought everybody’s dad was a clown.\"\\n* \"The Easter Bunny was in the passenger seat.\"\\n* \"The Easter Bunny head didn’t fit in the car. Like, he couldn’t sit normal, so his head was bent to the side.\"\\n* \"I remember he had his seat belt on, and he’s just like…\"\\n* \"I like to think about all the other people that saw that. Just in the',\n",
       " 'Nate_Bargatze_TK_2': '* \"Tuesday’s getting married, rehearsal’s Friday, wedding’s Saturday.”\\n* \"We gotta be there Monday for this wedding? How long is this wedding? It’s a week?”\\n* \"Everybody else just has a football or basketball jersey on. My uncle, his daughter’s getting married. He has his tuxedo jacket, pants, cummerbund, bowtie. No shirt.\"\\n* \"They forgot his shirt, and instead of waiting to go get it, he was like, “Let’s do it without it.”\\n* \"Like,',\n",
       " 'Russell_Peters': '* \"That’s really fucking racist, but since you asked, I have acid reflux.\"\\n* \"There is no way you can be Indian and not have fucking acid reflux. It’s inevitable.\"\\n* \"What? Son, it’s burning your esophagus.\"\\n* \"Dad, I want to assure you I have no phagus in me.\"\\n* \"You got it, don’t you, yellow guy?\"\\n\\n\\nThe funniest punchlines are:\\n\\n1. **\"That’s really fucking racist, but since you asked, I have acid reflux.\"**',\n",
       " 'Russell_Peters_2': '* \"Kate and Duplicate\"\\n* \"Pete and Repeat\"\\n* \"Tyrone and Tyclone\"\\n* \"Identical twins, that’s like bragging rights for you, you know I mean.\"\\n* \"Look at how good my balls are.\"\\n* \"My balls are so strong, they made one kid and then it made the exact same kid right away.\"\\n* \"You lift up your balls, sponsored by Xerox.\"\\n* \"Sponsored by Xerox.\"\\n* \"Copy and Paste\"\\n\\n\\nThe funniest punchlines are subjective, but here are some strong contenders',\n",
       " 'Sam_Morril': '* \"I have a negative-one rapes, so, you know. Statistically, you know…\"\\n* \"That’s not how I want to think about it, you know? You don’t want to think of yourself as a -block to some monster.\"\\n* \"I can’t tell you how often I’m coming out of a blackout like I should have done doubles instead.\"\\n* \"Have you tried living? I’m happy and I want to get fucked up.\"\\n* \"If I listened to all the voices in my head, I',\n",
       " 'Sam_Morril_2': '* \"It’s weird that they can do anti-smoking ads, but you can’t do pro-cigarette commercials. Isn’t that weird? They don’t give ’em a rebuttal.\"\\n* \"A hot girl walks up to a guy in the bar and asks to bum a cigarette, and he goes, oh, I don’t smoke. So then she goes outside and bums them from another guy, and they go home together and they fuck and that’s the whole commercial. There at the end, it just says, “Wouldn’t kill you',\n",
       " 'Trevor_Noah': '* \"I feel safe, like even if there’s a monster under the bed, he’d be like, “Is that a Russian?”\"\\n* \"You’ll find me at three a.m., barefoot, walking to the toilet, like, “Yes. Big boy got to make a pee-pee. No trouble over here. It’s potty time.”\"\\n* \"Ladies, every single one of you needs to learn the Russian accent.\"\\n* \"The next time you’re in a compromising position, you’re at a bar, waiting for',\n",
       " 'Trevor_Noah_2': '* \"You can’t do normal things with that voice. You are destined for greatness.\"\\n* \"It’s so unique. You can’t be silly. What are you making, prank phone calls? “Who the hell is this?!” “I’m not telling you.” [laughs]\"\\n* \"And yet, he still did. He still kept what was him.\"\\n* \"It was partly because of that voice. He would tell the joke, and it would just sound too epic for people to laugh.\"\\n* \"Ah, knock, knock.” People would',\n",
       " 'Tom_Segura': '* \"Isn\\'t that your sole responsibility?\"\\n* \"That\\'s what\\'s up.\"\\n* \"But don\\'t shoot my mom.\"\\n* \"Can we get a description before we agree to terms? How about a height and weight on old mom?\"\\n\\n\\nThe funniest punchlines are:\\n\\n* **\"Isn\\'t that your sole responsibility?\"** This line is funny because it highlights the absurdity of the situation. The speaker is clearly uncomfortable with the idea of being left alone in a trailer with a gun, but they try to play it cool by asking this pointed',\n",
       " 'Tom_Segura_2': '* \"It felt like the inside of my body hugged the outside of my body, you know?\"\\n* \"You are lord of the elevator shaft. You get to decide, like a king with his drawbridge.\"\\n* \"And you hit that. And then you see it close, and you’re like…\"\\n* \"Sometimes, a second later it opens, and you’re like, “Fuck!”\"\\n* \"You get nervous energy, like you’re a kid. You’re like, “I’m in trouble.”\"\\n\\n\\nThe funniest punchlines'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Below is a transcript from a stand-up comedy routine. Analyze the transcript and extract the quotes that are most likely to have made the audience laugh. List of quotes:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "for index, row in transcripts.iterrows():\n",
    "    comedian = row['comedian']\n",
    "    transcript = row['transcript'] \n",
    "    \n",
    "    prompt = f\"'''{transcript}'''\\n\\n{instruction}\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=120)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = generated_text.replace(prompt, \"\").strip()\n",
    "    results_dict[comedian] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': '1. \"So poor I remember, just so I could go to my senior prom, just so I could go to my senior prom, I had to sell my U.S. passport on the street.\"\\n2. \"Sold my passport on the street for 300 bucks to get to go to my prom.\"\\n3. \"Of course this was before 9/11 so… my bad, everybody.\"\\n4. \"Weird joke to clap for, but sure.\"\\n5. \"My mom actually should’ve been on one of the planes that crashed on',\n",
       " 'Anthony_Jeselnik_2': '1. \"I asked a friend for advice. Was like, “I’ve never talked to a group of people without getting paid a lot of money. How should I handle this?”\"\\n2. \"Anthony, just go up there and tell a story. Find one moment about you and your grandma you can share with everybody. And don’t tell a joke. Try not.”\\n3. \"You know what my favorite memory was? When I was like four years old, before I learned to read, Grandma would curl up with me on the couch, she had this Southern',\n",
       " 'Ali_Wong': '1. \"Don’t ever do that with your mom.\"\\n2. \"It was like the worst experience of my life.\"\\n3. \"She refused to let go of a Texas Instruments TI-82… manual.\"\\n4. \"The manual. She don’t even know… where the calculator is.\"\\n5. \"It was this calculator that bamboozled my generation.\"\\n6. \"It was like the Tesla of my time.\"\\n7. \"And my mom got so emotional about the manual and she was like, “You never know when you might',\n",
       " 'Ali_Wong_2': '1. \"Cause she knows that she’s got a century more to go.\"\\n2. \"I’m just kidding. She doesn’t have any black friends.\"\\n3. \"Life is not Rush Hour, the movie, OK?\"\\n4. \"When I say be there for me, I mean pay for me when my husband isn’t around to support me anymore.\"\\n5. \"Old Chinese ladies, they don’t give a fuck.\"\\n6. \"They got no shame.\"\\n7. \"They’re like, “I’m just',\n",
       " 'Chelsea_Peretti': '* \"It’s like that wedding portraiture, where it’s just like, two assholes back to back in the woods, just like… [laughing shrilly] “To the future!”\\n* \"Every photo, they were just like… [giggles shrilly] “Uh-oh, it’s us again.” [trills]\\n* \"My hubby made breakfast. My hubby fixed the door. My hubby is sleeping. He breathed in, he breathed out. He breathed in, he breathed out.”\\n* \"I just keep waiting for the day where she',\n",
       " 'Chelsea_Peretti_2': '1. \"People say I look just like you.\"\\n2. \"It’s actually to stop them from sweating, because why would you, you know, as a human?\"\\n3. \"Hi, everyone, same old me.\"\\n4. \"It worked. I did stop sweating out of my armpits, but I started sweating out of my butthole.\"\\n5. \"Oh, ho, ho, ho.\"\\n6. \"She is so fucking hot. Her armpits are bone-fucking-dry… just like I always dreamed of.\"\\n7. \"',\n",
       " 'Donald_Glover': '* \"tears streaming down his face, but he wasn’t crying. He wasn’t crying. Just tears, he was giving me this mean mug, he was like…\"\\n* \"What the fuck is wrong with this kid? What’s going on with this kid?\"\\n* \"The sweetest thing he was allowed was mints. He would… The sweetest thing he was allowed was mints.\"\\n* \"So his breath was so fresh… the vapors from his own mouth made his eyes water.\"\\n* \"Like, he’d be like, “Hello!” And',\n",
       " 'Donald_Glover_2': '1. \"Yeah, well, “if anybody ever tries to rape me, I’m just gonna shit on ’em.” “Yes, I will. I have no problem.”\\n2. \"Uh… Two things, lady. Number one, he’s a rapist. So his tolerance for gross stuff is probably pretty high. It’s probably pretty high.\"\\n3. \"You can shit on command? Like, you can just… You can just poop whenever you want to? Just be like… Hyah! He’s like, “Oh God, no!” Like',\n",
       " 'Hasan_Minhaj': '1. \"Are you fucking kidding? Thirteen episodes for this kid?\"\\n2. \"Every brown birthday party.\"\\n3. \"And that’s what makes us tough and resilient. It’s why we become cardiologists and win spelling bees.\"\\n4. \"Slapping is important. It elevates your game.\"\\n5. \"You ever seen an Indian kid win a spelling bee? Incredible! Ice water in the veins.\"\\n6. \"That kid won’t choke on camera. He’s been slapped on camera.\"\\n7. \"Look at that face.',\n",
       " 'Hasan_Minhaj_2': '1. “I know, getting into Stanford.”\\n2. “No, you have to live a life worth talking about, which is why I’m making it mandatory for everyone in this class to go to prom.”\\n3. “All 30 of us? We’re all going to prom? AP Calc? Us? Me, Jehovah’s Witness girl, Korean exchange students, going to the prom? Thirty for 30? All of us?”\\n4. “Hanson, this is not funny.”\\n5. “Whatever, it’s not going',\n",
       " 'Iliza_Shlesinger': '1. \"It’s so homey. I’d like to stay forever.”\\n2. \"Welcome to Fuckdome, Scott.\"\\n3. \"Should I buy a rug or eat dinner? I don’t know.\"\\n4. \"You want him to come in and be, like, “It’s so homey. I’d like to stay forever.” Yes, come closer. Like, that’s what you want.\"\\n5. \"Granted, I’m not married yet, so, technically, I’ve only had beginnings of relationships.\"',\n",
       " 'Iliza_Shlesinger_2': '1. \"You don’t want to wear your daytime clothes, ’cause… ’cause it’s nighttime.\"\\n2. \"You don’t want to wear nipple tassels.\"\\n3. \"No means no. Kindergarteners get it.\"\\n4. \"The blood’s gonna go from here to his dick, he’s gonna impale himself, he’s gonna sue you, and you ain’t got no money.\"\\n5. \"It’d be like if you have the worst day, you came home to your boyfriend, like… “I had',\n",
       " 'Jim_Gaffigan': '1. \"We got nothing for you. And you can’t use our bathroom.\"\\n2. \"Aw. Look at you try.\"\\n3. \"The fat pig is trying, the fat pig is trying, I…\"\\n4. \"Good show.” “You nailed it.” I don’t care. I like to eat! I like to eat.\"\\n5. \"Well, you must know your way around the kitchen. I know where the food is.\"\\n6. \"Well, you must love to cook. Look, I like to sleep. It doesn’',\n",
       " 'Jim_Gaffigan_2': '* \"I have friends that are mentally ill.\"\\n* \"Didn\\'t suspect a thing. Dog didn\\'t know it was his birthday. The dog didn\\'t know it had a birthday.\"\\n* \"Oh, one year equals seven for doggies? Okay. When I see a dog, I’ll do math. That’s not fulfilling some dog need, you know?\"\\n* \"There’s not a dog sitting in a bar right now going, “I’m not three, I’m 21! I can legally drink!”\"\\n*',\n",
       " 'Joe_List': '1. \"It’s one doctor. He knows all three body parts.\"\\n2. \"Ear, nose, throat. “Who do ya need?”\"\\n3. \"And they all kinda.\"\\n4. \"That’s when you’re ears ring. You got it? Yeah, it’s frustrating.\"\\n5. \"I thought it was called tinnitus, but then I watched a YouTube video, and the doctor in the video, he kept saying “tin-uh-dus.”\"\\n6. \"This guy’s a fake ass fucking retard doctor.',\n",
       " 'Joe_List_2': '1. \"You feel better than everybody behind you, don’t you?\"\\n2. \"Embarrassing, loser.\"\\n3. \"[yawns] For like five hours. [yawns]\"\\n4. \"I wanted him to die, I swear to God.\"\\n5. \"It’s like, if you were hungry on a plane, you were like, I’m hungry. Well you’re all right? Yeah, yeah I’m hungry. I like to let people know when I’m hungry. I think it’s important for people to know',\n",
       " 'John_Mulaney': '1. \"We made these big piles of clothes, we put the piles into these big boxes, then we put the boxes into the back of my car, and then they stayed there for four months.\"\\n2. \"And then one day my wife said, “Hey, you took that stuff to Goodwill, right?” And I said, “Of course I did! On an unrelated note, I’m going to walk out the front door right now.”\"\\n3. \"It was charitable, but it was also fast and violent, because I was throwing boxes at people.\"',\n",
       " 'John_Mulaney_2': '1. \"Go ahead and laugh. His name is ridiculous. That was his name. It was JJ Bittenbinder.\"\\n2. \"Oh, gee. [audience laughing] Very sorry, Radio City, did that make you uncomfortable? Well, guess what? You’re adults and he’s not even here.\"\\n3. \"He’s still got blood on his shoes. And he’s looking at you in the eye to tell you for the first time in your very young life that some adults find you incredibly attractive. [audience laughing] And they may just have',\n",
       " 'Jimmy_Yang': '1. \"Asian people, we don’t need Tinder anymore. We just go to BTS concerts. That’s how we do that parking lot pimping.\"\\n2. \"I’ve been dating a lot of tall girls lately, because it makes me look successful.\"\\n3. \"No, no. I think tall women are beautiful. But some of them like to wear heels. That’s just disrespect. Like, you’re already five inches taller than me. Why the fuck are you wearing heels? She’s like, it makes my ass look better. I',\n",
       " 'Jimmy_Yang_2': '1. \"But my parents, they’re like negative 9 generation, because they’re so frickin’ Chinese.\"\\n2. \"First of all, old Asian people, they don’t watch TV. They judge the TV.\"\\n3. \"He’s just sitting there, arms folded, judging the TV like–\"\\n4. \"He’s made some random noises around the house. Now whenever he sneezes, it’s never just a sneeze. It’s like a whole tsunami of sound waves that comes after.\"\\n5. \"It’',\n",
       " 'Louis_CK': '1. \"He was?\"\\n2. \"Yeah. Jesus was Jewish.\"\\n3. \"I don’t think so.\"\\n4. \"Dude, Jesus couldn’t be Jewish. Think about it.\"\\n5. \"You fucking think about it, you idiot.\"\\n6. \"What d– What was he then? You’re… What, was he Presbyterian? What was he? Catholic?\"\\n7. \"Jesus was Catholic and he had a gold chain with a cross.\"\\n8. \"And when they nailed him up, he was like, “Oh',\n",
       " 'Louis_CK_2': '1. \"I know you! Ha!\"\\n2. \"They’re so stupid! Incredibly stupid animals.\"\\n3. \"They don’t even know their own lives, they don’t even — they can’t even handle their own lives mentally.\"\\n4. \"I didn’t see what happened. I’m sorry, I… I don’t know anything now. Please help.\"\\n5. \"There it is, right there. It’s right there.\"\\n6. \"…that he can follow with his imagination.\"\\n\\n**Analysis:**',\n",
       " 'Nate_Bargatze': '1. \"Did you name her after Harper Lee, the author of To Kill a Mockingbird?\" And, you know, I’ve never thought about an author a day in my life, so… That never occurred to me. I mean, my middle name is Lee, and it just never crossed my mind.\"\\n2. \"I love having a kid. We… I love\\xa0when kids cry, it’s just innocent. I love how innocent it is. They cry over a tag in their shirt. I mean, they bawl. They don’t like… It',\n",
       " 'Nate_Bargatze_2': '1. \"First and second grade was awesome. Third grade, you’re like, “Okay.” They throw some stuff in, you’re like, “Oh, all right. All right.” It’s, uh… “Okay, learning it earlier than we used to, huh?” I don’t even know if that’s true, but…\"\\n2. \"She brought home Common Core math. That’s fun. It’s a new math they invented, no heads up. Just give it to parents that never learned it.\"\\n3. \"It’',\n",
       " 'Nate_Bargatze_TK': '1. \"Uh… It goes clown, then magic. There’s two steps. You can take them in either order.\"\\n2. \"I thought everybody’s dad was a clown.\"\\n3. \"That’s just how he left. How else would he come home?\"\\n4. \"The Easter Bunny was in the passenger seat.\"\\n5. \"The Easter Bunny head didn’t fit in the car. Like, he couldn’t sit normal, so his head was bent to the side.\"\\n6. \"And I remember he had his seat belt on',\n",
       " 'Nate_Bargatze_TK_2': '1. \"Tuesday’s getting married, rehearsal’s Friday, wedding’s Saturday.”\\n2. \"We gotta be there Monday for this wedding? How long is this wedding? It’s a week?”\\n3. \"Everybody else just has a football or basketball jersey on.\"\\n4. \"They forgot his shirt, and instead of waiting to go get it, he was like, “Let’s do it without it.”\\n5. \"Like, that’s… And he doesn’t have a body that’s like, “That’s cool,',\n",
       " 'Russell_Peters': '1. \"that’s really fucking racist, but since you asked, I have acid reflux.\"\\n2. \"There’s no way you can consume the food that we eat with that much spice, and that much oil, and that much butter, and not just have it burn a hole in your– as my dad would say– your esophagus.\"\\n3. \"Dad, I want to assure you I have no phagus in me.\"\\n4. \"No, no, son, esophagus.\"\\n5. \"I don’t care whose phagus you think this is',\n",
       " 'Russell_Peters_2': '1. \"If I have twin girls– because you’ve got to have fun with the names. If I have twin girls, these are going to be my daughters, it’s going to be Kate and Duplicate.\"\\n2. \"These are my boys, it’s Pete and Repeat.\"\\n3. \"If I had twins with a black girl, this is Tyrone and Tyclone.\"\\n4. \"Identical twins, that’s like bragging rights for you, you know I mean. That’s your way of going, look. Look at how good my balls',\n",
       " 'Sam_Morril': '* \"That is male privilege right there, isn’t it? I just told a room full of people I got roofied. I did not see one concerned face in here. Everyone in here is like I assume things worked out for you, and they did. Still weird, though.\"\\n* \"And I chugged it, and I woke up the next morning, and I was like oh. That guy’s a sexual predator.\"\\n* \"And my friend said you ruined his night. And I was like, that’s not how I want to think about it,',\n",
       " 'Sam_Morril_2': '* \"It’s weird that they can do anti-smoking ads, but you can’t do pro-cigarette commercials. Isn’t that weird? They don’t give ’em a rebuttal.\"\\n* \"A hot girl walks up to a guy in the bar and asks to bum a cigarette, and he goes, oh, I don’t smoke. So then she goes outside and bums them from another guy, and they go home together and they fuck and that’s the whole commercial. There at the end, it just says, “Wouldn’t kill you',\n",
       " 'Trevor_Noah': '1. \"You know how I know this? You know how I’ve learned? Because I’ve learned how to use the Russian accent for myself.\"\\n2. \"I’m not particularly comfortable in the house at night by myself. What I’m trying to say is I’m afraid of the dark.\"\\n3. \"And whenever that happens, I’m always faced with the eternal dilemma. When I go to the bathroom, do I turn the lights on and lose my sleep? Or do I leave the lights off and shit myself?\"\\n4. \"I',\n",
       " 'Trevor_Noah_2': '* \"You can’t do normal things with that voice. You are destined for greatness.\"\\n* \"You can’t be running in the streets: “And a Kit Kat, please.” No. No.\"\\n* \"It just doesn’t work. I remember when Nelson Mandela was still alive, and he would tell jokes at press conferences and events, and no one would laugh.\"\\n* \"Because everyone thought a man who had been in jail for 27 years couldn’t make a joke.\"\\n* \"He still kept what was him. It was partly because',\n",
       " 'Tom_Segura': '* \"Get the fuck out of here.\"\\n* \"You trying to get a sack?\"\\n* \"We could go do that.\"\\n* \"You don’t fuckin’ have it? Isn’t that your sole responsibility?\"\\n* \"Let’s go get it.\"\\n* \"I’ll go get it. You stay here and watch my place.\"\\n* \"That’s what’s up.\"\\n* \"But don’t shoot my mom.\"\\n* \"Can we get a description before we agree to terms? How about a height and weight on',\n",
       " 'Tom_Segura_2': '1. \"I got such a warm rush through my body. It felt like the inside of my body hugged the outside of my body, you know?\"\\n2. \"I was trying to figure out, “Why does this feel so good?” I think it’s a taste of power.\"\\n3. \"Like most of us, we have no power in our everyday lives. But if you’re alone in an elevator, -you are lord of the elevator shaft.\"\\n4. \"You get to decide, like a king with his drawbridge. There’s “Hold'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 23.58 GiB of which 39.44 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 23.16 GiB is allocated by PyTorch, and 122.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m pad_token_id \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token_id \u001b[38;5;28;01mif\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39meos_token_id \u001b[38;5;28;01melse\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/transformers/modeling_utils.py:2796\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2792\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2793\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2795\u001b[0m         )\n\u001b[0;32m-> 2796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 780 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 23.58 GiB of which 39.44 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 23.16 GiB is allocated by PyTorch, and 122.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "model.to(\"cuda\")\n",
    "pad_token_id = tokenizer.eos_token_id if tokenizer.eos_token_id else tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranscript\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minstruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m response \u001b[38;5;241m=\u001b[39m generated_text\u001b[38;5;241m.\u001b[39mreplace(prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/transformers/generation/utils.py:1914\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1906\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1907\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1908\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1909\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1911\u001b[0m     )\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m     )\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/transformers/generation/utils.py:2651\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2648\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2651\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2659\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:1174\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1171\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:931\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    928\u001b[0m     use_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m return_legacy_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, Cache):  \u001b[38;5;66;03m# kept for BC (non `Cache` `past_key_values` inputs)\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/modules/sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "\n",
    "for index, row in transcripts.iterrows():\n",
    "    comedian = row['comedian']\n",
    "    transcript = row['transcript']\n",
    "\n",
    "    prompt = f\"'''{transcript}'''\\n\\n{instruction}\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=120, pad_token_id=pad_token_id)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = generated_text.replace(prompt, \"\").strip()\n",
    "    results_dict[comedian] = response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
