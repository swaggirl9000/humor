{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM humor detection with Subspace based metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/Documents/humor/.venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:777: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79e4bb43f13459787d15ca6b59dc3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "from more_itertools import batched\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "MODEL_ID = \"google/gemma-2-9b-it\"\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"cuda:0\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    output_hidden_states=True  # Enable hidden states output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv('../data/stand_up_dataset/standup_data.csv')\n",
    "transcript = pd.read_csv('../data/stand_up_dataset/standup_transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = [\n",
    "    \"Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    \"The following is a stand-up comedy transcript. When performed in front of a live audience, which jokes do you think made the audience laugh?  List of quotes:\",\n",
    "    \"You are a person who enjoys aggressive humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    \"You are a person who enjoys self-enhancing humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"You are a person who enjoys self-deprecating humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"You are a person who enjoys dark humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"You are a person who enjoys affiliative humor. Extract the key humorous lines and punchlines for this stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"The following is a stand-up comedy transcript. What are the funniest punchlines from the transcript. List of quotes:\",\n",
    "    # \"Below is a transcript from a stand-up comedy routine. Analyze the transcript and extract the quotes that are most likely to have made the audience laugh. List of quotes:\",\n",
    "    # \"The following is a stand-up comedy transcript. When preformed in front of a live audience, which jokes do you think made the audience laugh? List of quotes:\",\n",
    "    # \"Pretend that you are a stand-up comedian reading the following stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"Pretend that you are a stand-up comedy fan reading the following stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    # \"Pretend that you are a stand-up comedy critic reading the following stand-up comedy transcript. Focus on the quotes highlighting the main comedic moments. List of quotes:\",\n",
    "    #\"Analyze the stand-up comedy transcript below. Which lines and punchlines do you think delivered the biggest laughs to the audience? List of quotes:\", \n",
    "    #\"As a person who enjoys witty, intellectual humor, extract the key humorous lines and punchlines from this stand-up comedy transcript. Focus on the quotes that demonstrate clever wordplay or insights. List of quotes:\",\n",
    "    #\"This is a transcript from a stand-up routine. Identify the lines and punchlines that likely had the strongest comedic impact during the performance. List of quotes:\",\n",
    "    #\"Pretend you're an audience member at this stand-up show. Which lines do you think got the biggest laughs? Focus on key moments of humor. List of quotes:\",\n",
    "    #\"This is a transcript of a live stand-up performance. Which quotes do you believe would have resonated the most with the audience? Focus on key punchlines. List of quotes:\",\n",
    "    #\"Imagine you are a comedian reviewing this stand-up routine. Identify the funniest moments and lines where the punchlines landed the hardest. List of quotes:\",\n",
    "    #\"Read through the stand-up comedy transcript and extract the lines that best capture the humor and timing of the performance. Focus on punchlines that likely had the audience laughing. List of quotes:\",\n",
    "    #\"This is a stand-up comedy transcript. Analyze the content and extract the lines that most effectively build up to or deliver punchlines. List of quotes:\",\n",
    "    #\"Pretend you're watching this performance live. What do you think were the standout comedic lines and punchlines that elicited the loudest laughs? List of quotes:\",\n",
    "    #\"Imagine you are writing a review of this stand-up performance. What lines and punchlines would you highlight as the funniest moments? List of quotes:\"\n",
    "]\n",
    "\n",
    "CONTENTS = [\n",
    "    \"\",\n",
    "    \"Sure, here are the key humorous lines:\",\n",
    "    \"Here are some lines and punchlines that could be funny:\",\n",
    "    \"Got it! Here are the main punchlines and comedic highlights:\",\n",
    "    # \"Here's a selection of the funniest quotes from the transcript:\",\n",
    "    # \"I've picked out the key humorous moments for you:\",\n",
    "    # \"Below are the standout lines and punchlines from the performance:\",\n",
    "    # \"Here's a breakdown of the top quotes that likely got the biggest laughs:\",\n",
    "    # \"Take a look at these key comedic lines from the routine:\",\n",
    "    # \"Here's a list of the most memorable punchlines from the set:\",\n",
    "    # \"Check out these quotes—some of the best comedic moments from the transcript:\",\n",
    "    # \"Here are the funniest moments and punchlines I found in the transcript:\",\n",
    "    # \"Here's what I've identified as the standout lines and punchlines in this comedy routine:\" \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>instruction</th>\n",
       "      <th>content</th>\n",
       "      <th>gt_input</th>\n",
       "      <th>model_input</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedian</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anthony_Jeselnik</th>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "      <td>1. So poor I remember, just so I could go to m...</td>\n",
       "      <td>Extract the key humorous lines and punchlines ...</td>\n",
       "      <td></td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthony_Jeselnik</th>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "      <td>1. So poor I remember, just so I could go to m...</td>\n",
       "      <td>Extract the key humorous lines and punchlines ...</td>\n",
       "      <td>Sure, here are the key humorous lines:</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthony_Jeselnik</th>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "      <td>1. So poor I remember, just so I could go to m...</td>\n",
       "      <td>Extract the key humorous lines and punchlines ...</td>\n",
       "      <td>Here are some lines and punchlines that could ...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthony_Jeselnik</th>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "      <td>1. So poor I remember, just so I could go to m...</td>\n",
       "      <td>Extract the key humorous lines and punchlines ...</td>\n",
       "      <td>Got it! Here are the main punchlines and comed...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthony_Jeselnik</th>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "      <td>1. So poor I remember, just so I could go to m...</td>\n",
       "      <td>The following is a stand-up comedy transcript....</td>\n",
       "      <td></td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nThe following is a s...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nThe following is a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom_Segura_3</th>\n",
       "      <td>Probably checked in to 400 hotels this year. A...</td>\n",
       "      <td>1. And the guy goes, “Whoa. Are you Japanese?”...</td>\n",
       "      <td>You are a person who enjoys aggressive humor. ...</td>\n",
       "      <td>Got it! Here are the main punchlines and comed...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom_Segura_3</th>\n",
       "      <td>Probably checked in to 400 hotels this year. A...</td>\n",
       "      <td>1. And the guy goes, “Whoa. Are you Japanese?”...</td>\n",
       "      <td>You are a person who enjoys self-enhancing hum...</td>\n",
       "      <td></td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom_Segura_3</th>\n",
       "      <td>Probably checked in to 400 hotels this year. A...</td>\n",
       "      <td>1. And the guy goes, “Whoa. Are you Japanese?”...</td>\n",
       "      <td>You are a person who enjoys self-enhancing hum...</td>\n",
       "      <td>Sure, here are the key humorous lines:</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom_Segura_3</th>\n",
       "      <td>Probably checked in to 400 hotels this year. A...</td>\n",
       "      <td>1. And the guy goes, “Whoa. Are you Japanese?”...</td>\n",
       "      <td>You are a person who enjoys self-enhancing hum...</td>\n",
       "      <td>Here are some lines and punchlines that could ...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom_Segura_3</th>\n",
       "      <td>Probably checked in to 400 hotels this year. A...</td>\n",
       "      <td>1. And the guy goes, “Whoa. Are you Japanese?”...</td>\n",
       "      <td>You are a person who enjoys self-enhancing hum...</td>\n",
       "      <td>Got it! Here are the main punchlines and comed...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         transcript  \\\n",
       "comedian                                                              \n",
       "Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...   \n",
       "Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...   \n",
       "Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...   \n",
       "Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...   \n",
       "Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...   \n",
       "...                                                             ...   \n",
       "Tom_Segura_3      Probably checked in to 400 hotels this year. A...   \n",
       "Tom_Segura_3      Probably checked in to 400 hotels this year. A...   \n",
       "Tom_Segura_3      Probably checked in to 400 hotels this year. A...   \n",
       "Tom_Segura_3      Probably checked in to 400 hotels this year. A...   \n",
       "Tom_Segura_3      Probably checked in to 400 hotels this year. A...   \n",
       "\n",
       "                                                       ground_truth  \\\n",
       "comedian                                                              \n",
       "Anthony_Jeselnik  1. So poor I remember, just so I could go to m...   \n",
       "Anthony_Jeselnik  1. So poor I remember, just so I could go to m...   \n",
       "Anthony_Jeselnik  1. So poor I remember, just so I could go to m...   \n",
       "Anthony_Jeselnik  1. So poor I remember, just so I could go to m...   \n",
       "Anthony_Jeselnik  1. So poor I remember, just so I could go to m...   \n",
       "...                                                             ...   \n",
       "Tom_Segura_3      1. And the guy goes, “Whoa. Are you Japanese?”...   \n",
       "Tom_Segura_3      1. And the guy goes, “Whoa. Are you Japanese?”...   \n",
       "Tom_Segura_3      1. And the guy goes, “Whoa. Are you Japanese?”...   \n",
       "Tom_Segura_3      1. And the guy goes, “Whoa. Are you Japanese?”...   \n",
       "Tom_Segura_3      1. And the guy goes, “Whoa. Are you Japanese?”...   \n",
       "\n",
       "                                                        instruction  \\\n",
       "comedian                                                              \n",
       "Anthony_Jeselnik  Extract the key humorous lines and punchlines ...   \n",
       "Anthony_Jeselnik  Extract the key humorous lines and punchlines ...   \n",
       "Anthony_Jeselnik  Extract the key humorous lines and punchlines ...   \n",
       "Anthony_Jeselnik  Extract the key humorous lines and punchlines ...   \n",
       "Anthony_Jeselnik  The following is a stand-up comedy transcript....   \n",
       "...                                                             ...   \n",
       "Tom_Segura_3      You are a person who enjoys aggressive humor. ...   \n",
       "Tom_Segura_3      You are a person who enjoys self-enhancing hum...   \n",
       "Tom_Segura_3      You are a person who enjoys self-enhancing hum...   \n",
       "Tom_Segura_3      You are a person who enjoys self-enhancing hum...   \n",
       "Tom_Segura_3      You are a person who enjoys self-enhancing hum...   \n",
       "\n",
       "                                                            content  \\\n",
       "comedian                                                              \n",
       "Anthony_Jeselnik                                                      \n",
       "Anthony_Jeselnik             Sure, here are the key humorous lines:   \n",
       "Anthony_Jeselnik  Here are some lines and punchlines that could ...   \n",
       "Anthony_Jeselnik  Got it! Here are the main punchlines and comed...   \n",
       "Anthony_Jeselnik                                                      \n",
       "...                                                             ...   \n",
       "Tom_Segura_3      Got it! Here are the main punchlines and comed...   \n",
       "Tom_Segura_3                                                          \n",
       "Tom_Segura_3                 Sure, here are the key humorous lines:   \n",
       "Tom_Segura_3      Here are some lines and punchlines that could ...   \n",
       "Tom_Segura_3      Got it! Here are the main punchlines and comed...   \n",
       "\n",
       "                                                           gt_input  \\\n",
       "comedian                                                              \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...   \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...   \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...   \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...   \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nThe following is a s...   \n",
       "...                                                             ...   \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...   \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...   \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...   \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...   \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...   \n",
       "\n",
       "                                                        model_input  \n",
       "comedian                                                             \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...  \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...  \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...  \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...  \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nThe following is a s...  \n",
       "...                                                             ...  \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...  \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...  \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...  \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...  \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...  \n",
       "\n",
       "[816 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = ground_truth.groupby(\"comedian\")[\"sentence\"].apply(list).apply(lambda sentences: \"\\n\".join([f\"{i + 1}. {s}\" for i, s in enumerate(sentences)]))\n",
    "df = transcript.set_index(\"comedian\").join(gt).rename(columns={\"sentence\": \"ground_truth\"})\n",
    "\n",
    "df[\"instruction\"] = [INSTRUCTIONS] * len(df)\n",
    "df = df.explode(\"instruction\")\n",
    "df[\"content\"] = [CONTENTS] * len(df)\n",
    "df = df.explode(\"content\")\n",
    "\n",
    "def gt_chat_template(row):\n",
    "    return tokenizer.apply_chat_template([\n",
    "        # {\"role\": \"system\", \"content\": \"\"},\n",
    "        {\"role\": \"user\", \"content\": row[\"instruction\"] + \"\\n\" + row[\"transcript\"]},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"content\"] + \"\\n\" + row[\"ground_truth\"]},\n",
    "    ], tokenize=False)\n",
    "\n",
    "df[\"gt_input\"] = df.apply(gt_chat_template, axis=1)\n",
    "\n",
    "def model_chat_template(row):\n",
    "    return tokenizer.apply_chat_template([\n",
    "        # {\"role\": \"system\", \"content\": \"\"},\n",
    "        {\"role\": \"user\", \"content\": row[\"instruction\"] + \"\\n\" + row[\"transcript\"]},\n",
    "    ], tokenize=False)\n",
    "\n",
    "df[\"model_input\"] = df.apply(model_chat_template, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = model.lm_head.weight.float().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 62.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# use unembedding tokenization form\n",
    "def get_gt_representation(batch_of_strs: list, subspace_size: int = 8) -> torch.Tensor:\n",
    "    inputs = tokenizer(batch_of_strs, return_tensors=\"pt\", padding=True, truncation=False).to(model.device)\n",
    "    *_, subs_repr = torch.pca_lowrank(U[inputs[\"input_ids\"]], q=subspace_size)\n",
    "    return subs_repr\n",
    "\n",
    "gt_representations = {\n",
    "    comedian: get_gt_representation(batch.tolist())\n",
    "    for comedian, batch in tqdm(df.groupby(\"comedian\")[\"model_input\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3584, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_representations[\"Ali_Wong\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51 [00:00<?, ?it/s]The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "  6%|▌         | 3/51 [00:54<14:36, 18.26s/it]"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 23.54 GiB of which 28.56 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 386.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m subs_repr\n\u001b[1;32m     11\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m---> 13\u001b[0m output_representations \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomedian\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mget_output_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcomedian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomedian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgt_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m}\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m subs_repr\n\u001b[1;32m     11\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     13\u001b[0m output_representations \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 14\u001b[0m     comedian: \u001b[43m[\u001b[49m\u001b[43mget_output_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m comedian, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomedian\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgt_input\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     16\u001b[0m }\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m subs_repr\n\u001b[1;32m     11\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     13\u001b[0m output_representations \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 14\u001b[0m     comedian: [\u001b[43mget_output_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batched(batch\u001b[38;5;241m.\u001b[39mtolist(), BATCH_SIZE)]\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m comedian, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomedian\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgt_input\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     16\u001b[0m }\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m, in \u001b[0;36mget_output_representation\u001b[0;34m(batch_of_strs, number_of_tokens, subspace_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(batch_of_strs, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[0;32m----> 5\u001b[0m     ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber_of_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;241m*\u001b[39m_, subs_repr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mpca_lowrank(U[ids], q\u001b[38;5;241m=\u001b[39msubspace_size)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m subs_repr\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:2047\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2039\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2040\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2041\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2042\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2043\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2044\u001b[0m     )\n\u001b[1;32m   2046\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2047\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2048\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2058\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2060\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2061\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2066\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2067\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:3007\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3004\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3007\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3010\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py:1047\u001b[0m, in \u001b[0;36mGemma2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   1045\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1047\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py:890\u001b[0m, in \u001b[0;36mGemma2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    879\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    880\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    881\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         cache_position,\n\u001b[1;32m    888\u001b[0m     )\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 890\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py:604\u001b[0m, in \u001b[0;36mGemma2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    601\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 604\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m    614\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py:253\u001b[0m, in \u001b[0;36mGemma2Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    250\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m+\u001b[39m causal_mask\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# upcast attention to fp32\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(query_states\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    254\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(attn_weights, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    255\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attn_weights, value_states)\n",
      "File \u001b[0;32m~/Documents/humor/.venv/lib/python3.11/site-packages/torch/nn/functional.py:2142\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2140\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim)\n\u001b[1;32m   2141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2142\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 23.54 GiB of which 28.56 MiB is free. Including non-PyTorch memory, this process has 23.27 GiB memory in use. Of the allocated memory 22.40 GiB is allocated by PyTorch, and 386.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "def get_output_representation(batch_of_strs: list, number_of_tokens: int = 128, subspace_size: int = 8) -> torch.Tensor:\n",
    "    inputs = tokenizer(batch_of_strs, return_tensors=\"pt\", padding=True, truncation=False).to(model.device)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        ids = model.generate(**inputs, max_new_tokens=number_of_tokens)\n",
    "    \n",
    "    *_, subs_repr = torch.pca_lowrank(U[ids], q=subspace_size)\n",
    "    return subs_repr\n",
    "        \n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "output_representations = {\n",
    "    comedian: [get_output_representation(x) for x in batched(batch.tolist(), BATCH_SIZE)]\n",
    "    for comedian, batch in tqdm(df.groupby(\"comedian\")[\"gt_input\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 4998.70it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for comedian in tqdm(gt_representations.keys()):\n",
    "    gt_reference_subspaces = gt_representations[comedian]\n",
    "    out_reference_subspaces = output_representations[comedian]\n",
    "\n",
    "    A = gt_reference_subspaces.mT @ out_reference_subspaces\n",
    "    scores[comedian] = A.matrix_power(2).diagonal(dim1=1,dim2=2).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>instruction</th>\n",
       "      <th>content</th>\n",
       "      <th>gt_input</th>\n",
       "      <th>model_input</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedian</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anthony_Jeselnik</th>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "      <td>1. So poor I remember, just so I could go to m...</td>\n",
       "      <td>Extract the key humorous lines and punchlines ...</td>\n",
       "      <td></td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthony_Jeselnik</th>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "      <td>1. So poor I remember, just so I could go to m...</td>\n",
       "      <td>Extract the key humorous lines and punchlines ...</td>\n",
       "      <td>Sure, here are the key humorous lines:</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthony_Jeselnik</th>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "      <td>1. So poor I remember, just so I could go to m...</td>\n",
       "      <td>Extract the key humorous lines and punchlines ...</td>\n",
       "      <td>Here are some lines and punchlines that could ...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthony_Jeselnik</th>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "      <td>1. So poor I remember, just so I could go to m...</td>\n",
       "      <td>Extract the key humorous lines and punchlines ...</td>\n",
       "      <td>Got it! Here are the main punchlines and comed...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nExtract the key humo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthony_Jeselnik</th>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "      <td>1. So poor I remember, just so I could go to m...</td>\n",
       "      <td>The following is a stand-up comedy transcript....</td>\n",
       "      <td></td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nThe following is a s...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nThe following is a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom_Segura_3</th>\n",
       "      <td>Probably checked in to 400 hotels this year. A...</td>\n",
       "      <td>1. And the guy goes, “Whoa. Are you Japanese?”...</td>\n",
       "      <td>You are a person who enjoys aggressive humor. ...</td>\n",
       "      <td>Got it! Here are the main punchlines and comed...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom_Segura_3</th>\n",
       "      <td>Probably checked in to 400 hotels this year. A...</td>\n",
       "      <td>1. And the guy goes, “Whoa. Are you Japanese?”...</td>\n",
       "      <td>You are a person who enjoys self-enhancing hum...</td>\n",
       "      <td></td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom_Segura_3</th>\n",
       "      <td>Probably checked in to 400 hotels this year. A...</td>\n",
       "      <td>1. And the guy goes, “Whoa. Are you Japanese?”...</td>\n",
       "      <td>You are a person who enjoys self-enhancing hum...</td>\n",
       "      <td>Sure, here are the key humorous lines:</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom_Segura_3</th>\n",
       "      <td>Probably checked in to 400 hotels this year. A...</td>\n",
       "      <td>1. And the guy goes, “Whoa. Are you Japanese?”...</td>\n",
       "      <td>You are a person who enjoys self-enhancing hum...</td>\n",
       "      <td>Here are some lines and punchlines that could ...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom_Segura_3</th>\n",
       "      <td>Probably checked in to 400 hotels this year. A...</td>\n",
       "      <td>1. And the guy goes, “Whoa. Are you Japanese?”...</td>\n",
       "      <td>You are a person who enjoys self-enhancing hum...</td>\n",
       "      <td>Got it! Here are the main punchlines and comed...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "      <td>&lt;bos&gt;&lt;start_of_turn&gt;user\\nYou are a person who...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         transcript  \\\n",
       "comedian                                                              \n",
       "Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...   \n",
       "Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...   \n",
       "Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...   \n",
       "Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...   \n",
       "Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...   \n",
       "...                                                             ...   \n",
       "Tom_Segura_3      Probably checked in to 400 hotels this year. A...   \n",
       "Tom_Segura_3      Probably checked in to 400 hotels this year. A...   \n",
       "Tom_Segura_3      Probably checked in to 400 hotels this year. A...   \n",
       "Tom_Segura_3      Probably checked in to 400 hotels this year. A...   \n",
       "Tom_Segura_3      Probably checked in to 400 hotels this year. A...   \n",
       "\n",
       "                                                       ground_truth  \\\n",
       "comedian                                                              \n",
       "Anthony_Jeselnik  1. So poor I remember, just so I could go to m...   \n",
       "Anthony_Jeselnik  1. So poor I remember, just so I could go to m...   \n",
       "Anthony_Jeselnik  1. So poor I remember, just so I could go to m...   \n",
       "Anthony_Jeselnik  1. So poor I remember, just so I could go to m...   \n",
       "Anthony_Jeselnik  1. So poor I remember, just so I could go to m...   \n",
       "...                                                             ...   \n",
       "Tom_Segura_3      1. And the guy goes, “Whoa. Are you Japanese?”...   \n",
       "Tom_Segura_3      1. And the guy goes, “Whoa. Are you Japanese?”...   \n",
       "Tom_Segura_3      1. And the guy goes, “Whoa. Are you Japanese?”...   \n",
       "Tom_Segura_3      1. And the guy goes, “Whoa. Are you Japanese?”...   \n",
       "Tom_Segura_3      1. And the guy goes, “Whoa. Are you Japanese?”...   \n",
       "\n",
       "                                                        instruction  \\\n",
       "comedian                                                              \n",
       "Anthony_Jeselnik  Extract the key humorous lines and punchlines ...   \n",
       "Anthony_Jeselnik  Extract the key humorous lines and punchlines ...   \n",
       "Anthony_Jeselnik  Extract the key humorous lines and punchlines ...   \n",
       "Anthony_Jeselnik  Extract the key humorous lines and punchlines ...   \n",
       "Anthony_Jeselnik  The following is a stand-up comedy transcript....   \n",
       "...                                                             ...   \n",
       "Tom_Segura_3      You are a person who enjoys aggressive humor. ...   \n",
       "Tom_Segura_3      You are a person who enjoys self-enhancing hum...   \n",
       "Tom_Segura_3      You are a person who enjoys self-enhancing hum...   \n",
       "Tom_Segura_3      You are a person who enjoys self-enhancing hum...   \n",
       "Tom_Segura_3      You are a person who enjoys self-enhancing hum...   \n",
       "\n",
       "                                                            content  \\\n",
       "comedian                                                              \n",
       "Anthony_Jeselnik                                                      \n",
       "Anthony_Jeselnik             Sure, here are the key humorous lines:   \n",
       "Anthony_Jeselnik  Here are some lines and punchlines that could ...   \n",
       "Anthony_Jeselnik  Got it! Here are the main punchlines and comed...   \n",
       "Anthony_Jeselnik                                                      \n",
       "...                                                             ...   \n",
       "Tom_Segura_3      Got it! Here are the main punchlines and comed...   \n",
       "Tom_Segura_3                                                          \n",
       "Tom_Segura_3                 Sure, here are the key humorous lines:   \n",
       "Tom_Segura_3      Here are some lines and punchlines that could ...   \n",
       "Tom_Segura_3      Got it! Here are the main punchlines and comed...   \n",
       "\n",
       "                                                           gt_input  \\\n",
       "comedian                                                              \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...   \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...   \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...   \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...   \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nThe following is a s...   \n",
       "...                                                             ...   \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...   \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...   \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...   \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...   \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...   \n",
       "\n",
       "                                                        model_input  \n",
       "comedian                                                             \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...  \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...  \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...  \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nExtract the key humo...  \n",
       "Anthony_Jeselnik  <bos><start_of_turn>user\\nThe following is a s...  \n",
       "...                                                             ...  \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...  \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...  \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...  \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...  \n",
       "Tom_Segura_3      <bos><start_of_turn>user\\nYou are a person who...  \n",
       "\n",
       "[816 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.53843395149006"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(scores, index=range(len(scores))).to_csv(\"scores.csv\")\n",
    "df = pd.DataFrame(list(scores.items()), columns=['Comedian', 'Score'])\n",
    "df[\"Score\"].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/subspace_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"../data/subspace_scores/scores_{MODEL_ID.rsplit('/')[-1]}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spearman's rank correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/stand_up_dataset/gemma_answers.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m gemma_metric \u001b[38;5;241m=\u001b[39m bipartite_metric(model, ground_truth)\n\u001b[0;32m---> 11\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(gemma_metric, \u001b[43mdf\u001b[49m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomedian\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_df1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_df2\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     12\u001b[0m correlation, p_value \u001b[38;5;241m=\u001b[39m spearmanr(merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore_df1\u001b[39m\u001b[38;5;124m'\u001b[39m], merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore_df2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrelation: \u001b[39m\u001b[38;5;124m\"\u001b[39m, correlation)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"..\")\n",
    "from scipy.stats import spearmanr\n",
    "from humor.bipartite_metric import bipartite_metric\n",
    "\n",
    "ground_truth = pd.read_csv('../data/stand_up_dataset/standup_data.csv')\n",
    "model = pd.read_csv('../data/stand_up_dataset/gemma_answers.csv')\n",
    "\n",
    "gemma_metric = bipartite_metric(model, ground_truth)\n",
    "merged_df = pd.merge(gemma_metric, df, on='comedian', suffixes=('_df1', '_df2'))\n",
    "correlation, p_value = spearmanr(merged_df['score_df1'], merged_df['score_df2'])\n",
    "print(\"Correlation: \", correlation)\n",
    "print(\"p_value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
