{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic comparison of simply comparing how many of the sentences the model got correct in terms of the extracted ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv('/home/ada/humor/humor/standup_data.csv')\n",
    "model = pd.read_csv('/home/ada/humor/humor/gemma_answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['comedian', 'laugh_start', 'laugh_end', 'sentence'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedian</th>\n",
       "      <th>laugh_start</th>\n",
       "      <th>laugh_end</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>14.268125</td>\n",
       "      <td>19.352170</td>\n",
       "      <td>I was babysitting this kid once, this mean kid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>33.292292</td>\n",
       "      <td>34.182586</td>\n",
       "      <td>The sweetest thing he was allowed was mints. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>37.790618</td>\n",
       "      <td>53.441041</td>\n",
       "      <td>So he would steal mints by the handful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>68.880605</td>\n",
       "      <td>73.824077</td>\n",
       "      <td>And I would take him to the park and I was the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>85.491608</td>\n",
       "      <td>88.607636</td>\n",
       "      <td>You know, we'd trade jerk- chicken recipes and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        comedian  laugh_start  laugh_end  \\\n",
       "0  Donald_Glover    14.268125  19.352170   \n",
       "1  Donald_Glover    33.292292  34.182586   \n",
       "2  Donald_Glover    37.790618  53.441041   \n",
       "3  Donald_Glover    68.880605  73.824077   \n",
       "4  Donald_Glover    85.491608  88.607636   \n",
       "\n",
       "                                            sentence  \n",
       "0  I was babysitting this kid once, this mean kid...  \n",
       "1  The sweetest thing he was allowed was mints. H...  \n",
       "2            So he would steal mints by the handful.  \n",
       "3  And I would take him to the park and I was the...  \n",
       "4  You know, we'd trade jerk- chicken recipes and...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comedian</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>My mom actually should've been on one of the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>When I was a kid, like nine years old, I'd com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>I've never talked to a group of people without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>And I know my grandma loved it too, because it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Comedian                                           Sentence\n",
       "0    Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...\n",
       "1    Anthony_Jeselnik  My mom actually should've been on one of the p...\n",
       "2    Anthony_Jeselnik  When I was a kid, like nine years old, I'd com...\n",
       "3  Anthony_Jeselnik_2  I've never talked to a group of people without...\n",
       "4  Anthony_Jeselnik_2  And I know my grandma loved it too, because it..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's calculate the score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, simplify the sentences by changing them to all lowercase and removing punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def simple_sentence(sentence):\n",
    "    cleaned_sentence = sentence.lower()\n",
    "    cleaned_sentence = re.sub(r'[^\\w\\s]', '', cleaned_sentence)\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the score by first checking if the string matches entirely or is in the ground truth. If this is not the case, move onto fuzzy string matching to see the similarity of the responses. If the score is above 50%, we can add this to the total score. The score is the average of correct responses per transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = {}\n",
    "\n",
    "for index, row in ground_truth.iterrows():\n",
    "    comedian_name = row['comedian']\n",
    "    truth = row['sentence']   \n",
    "    simple_truth = simple_sentence(truth)\n",
    "    matching_rows = model[model['Comedian'] == comedian_name]\n",
    "    \n",
    "    score = 0\n",
    "    num_sentences = set()\n",
    "\n",
    "    if truth not in found:\n",
    "        found[truth] = [comedian_name, False, score, 0]  \n",
    "\n",
    "    for index2, row2 in matching_rows.iterrows():\n",
    "        model_answer = row2['Sentence']      \n",
    "        simple_model_answer = simple_sentence(model_answer)\n",
    "        num_sentences.add(model_answer)\n",
    "        \n",
    "        if simple_truth == simple_model_answer or simple_model_answer in simple_truth:\n",
    "            score = 100 \n",
    "            found[truth][0] = comedian_name  \n",
    "            found[truth][1] = True \n",
    "            found[truth][2] = score\n",
    "        else:\n",
    "            fuzzy_score = fuzz.partial_ratio(simple_truth, simple_model_answer)\n",
    "            if fuzzy_score > 60:\n",
    "                found[truth][0] = comedian_name \n",
    "                found[truth][1] = True\n",
    "                if fuzzy_score >  found[truth][2]:\n",
    "                    found[truth][2] = fuzzy_score\n",
    "    found[truth][3] = len(num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(found):\n",
    "    correct_guesses = {}\n",
    "    num_sentences = {}\n",
    "    \n",
    "    for val in found.values():\n",
    "        comedian_name = val[0]\n",
    "        number_of_sentences = val[3]\n",
    "        if comedian_name not in correct_guesses:\n",
    "            correct_guesses[comedian_name] = val[2]\n",
    "            num_sentences[comedian_name] = number_of_sentences\n",
    "        else:\n",
    "            correct_guesses[comedian_name] += val[2]\n",
    "    \n",
    "    for comedian_name, score in correct_guesses.items():\n",
    "        correct_guesses[comedian_name] = (correct_guesses[comedian_name]/num_sentences[comedian_name]) \n",
    "        \n",
    "    return correct_guesses \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Donald_Glover': 33.333333333333336,\n",
       " 'Donald_Glover_2': 126.66666666666667,\n",
       " 'Anthony_Jeselnik': 100.0,\n",
       " 'Anthony_Jeselnik_2': 66.0,\n",
       " 'Chelsea_Peretti': 110.33333333333333,\n",
       " 'Chelsea_Peretti_2': 50.0,\n",
       " 'Louis_CK': 106.8,\n",
       " 'Louis_CK_2': 50.0,\n",
       " 'John_Mulaney': 53.6,\n",
       " 'John_Mulaney_2': 42.75,\n",
       " 'Ali_Wong': 0.0,\n",
       " 'Ali_Wong_2': 66.66666666666667,\n",
       " 'Hasan_Minhaj': 50.0,\n",
       " 'Hasan_Minhaj_2': 50.0,\n",
       " 'Iliza_Shlesinger': 54.666666666666664,\n",
       " 'Iliza_Shlesinger_2': 50.0,\n",
       " 'Jim_Gaffigan': 82.25,\n",
       " 'Jim_Gaffigan_2': 81.0,\n",
       " 'Joe_List': 50.0,\n",
       " 'Joe_List_2': 50.0,\n",
       " 'Jimmy_Yang': 0.0,\n",
       " 'Jimmy_Yang_2': 75.0,\n",
       " 'Nate_Bargatze': 60.333333333333336,\n",
       " 'Nate_Bargatze_2': 0.0,\n",
       " 'Nate_Bargatze_TK': 25.0,\n",
       " 'Nate_Bargatze_TK_2': 20.0,\n",
       " 'Russell_Peters': 49.25,\n",
       " 'Russell_Peters_2': 76.4,\n",
       " 'Sam_Morril': 97.0,\n",
       " 'Sam_Morril_2': 41.5,\n",
       " 'Trevor_Noah': 46.0,\n",
       " 'Trevor_Noah_2': 60.333333333333336,\n",
       " 'Tom_Segura': 60.0,\n",
       " 'Tom_Segura_2': 150.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start from the model to avoid duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anthony_Jeselnik': 3, 'Anthony_Jeselnik_2': 3, 'Ali_Wong': 4, 'Ali_Wong_2': 3, 'Chelsea_Peretti': 3, 'Chelsea_Peretti_2': 4, 'Donald_Glover': 3, 'Donald_Glover_2': 3, 'Hasan_Minhaj': 4, 'Hasan_Minhaj_2': 4, 'Iliza_Shlesinger': 3, 'Iliza_Shlesinger_2': 2, 'Jim_Gaffigan': 4, 'Jim_Gaffigan_2': 3, 'Joe_List': 4, 'Joe_List_2': 4, 'John_Mulaney': 5, 'John_Mulaney_2': 4, 'Jimmy_Yang': 2, 'Jimmy_Yang_2': 4, 'Louis_CK': 5, 'Louis_CK_2': 4, 'Nate_Bargatze': 3, 'Nate_Bargatze_2': 4, 'Nate_Bargatze_TK': 4, 'Nate_Bargatze_TK_2': 5, 'Russell_Peters': 4, 'Russell_Peters_2': 5, 'Sam_Morril': 2, 'Sam_Morril_2': 4, 'Trevor_Noah': 2, 'Trevor_Noah_2': 3, 'Tom_Segura': 5, 'Tom_Segura_2': 2}\n"
     ]
    }
   ],
   "source": [
    "quotes_count_dict = {}\n",
    "for comedian in model['Comedian']:\n",
    "    if comedian in quotes_count_dict:\n",
    "        quotes_count_dict[comedian] += 1\n",
    "    else:\n",
    "        quotes_count_dict[comedian] = 1\n",
    "\n",
    "print(quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = {}\n",
    "\n",
    "for index, row in model.iterrows():\n",
    "    comedian_name = row['Comedian']\n",
    "    model_output = row['Sentence']   \n",
    "    simple_model_output = simple_sentence(model_output)\n",
    "    matching = ground_truth[ground_truth['comedian'] == comedian_name]\n",
    "\n",
    "    if truth not in found:\n",
    "        found[model_output] = [comedian_name, 0]  \n",
    "\n",
    "    for index2, row2 in matching.iterrows():\n",
    "        truth = row2['sentence']\n",
    "        simple_truth = simple_sentence(truth)\n",
    "\n",
    "        if simple_truth == simple_model_output or simple_model_output in simple_truth:\n",
    "            found[model_output][0] = comedian_name  \n",
    "            found[model_output][1] = 100\n",
    "        else:\n",
    "            fuzzy_score = fuzz.partial_ratio(simple_truth, simple_model_output)\n",
    "            if fuzzy_score > 60:\n",
    "                found[model_output][0] = comedian_name \n",
    "                found[model_output][1] = max(found[model_output][1], fuzzy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(found, num_sentences):\n",
    "    correct_guesses = {}\n",
    "    \n",
    "    for val in found.values():\n",
    "        comedian_name = val[0]\n",
    "        if comedian_name not in correct_guesses:\n",
    "            correct_guesses[comedian_name] = val[1]\n",
    "        else:\n",
    "            correct_guesses[comedian_name] += val[1]\n",
    "    \n",
    "    for comedian_name, score in correct_guesses.items():\n",
    "        correct_guesses[comedian_name] = (correct_guesses[comedian_name]/num_sentences[comedian_name]) \n",
    "        \n",
    "    return correct_guesses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found, quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': 100.0,\n",
       " 'Anthony_Jeselnik_2': 66.0,\n",
       " 'Ali_Wong': 0.0,\n",
       " 'Ali_Wong_2': 66.66666666666667,\n",
       " 'Chelsea_Peretti': 56.333333333333336,\n",
       " 'Chelsea_Peretti_2': 50.0,\n",
       " 'Donald_Glover': 33.333333333333336,\n",
       " 'Donald_Glover_2': 82.66666666666667,\n",
       " 'Hasan_Minhaj': 50.0,\n",
       " 'Hasan_Minhaj_2': 50.0,\n",
       " 'Iliza_Shlesinger': 54.666666666666664,\n",
       " 'Iliza_Shlesinger_2': 81.0,\n",
       " 'Jim_Gaffigan': 87.25,\n",
       " 'Jim_Gaffigan_2': 60.333333333333336,\n",
       " 'Joe_List': 67.25,\n",
       " 'Joe_List_2': 50.0,\n",
       " 'John_Mulaney': 40.0,\n",
       " 'John_Mulaney_2': 42.75,\n",
       " 'Jimmy_Yang': 0.0,\n",
       " 'Jimmy_Yang_2': 75.0,\n",
       " 'Louis_CK': 100.0,\n",
       " 'Louis_CK_2': 65.25,\n",
       " 'Nate_Bargatze': 60.333333333333336,\n",
       " 'Nate_Bargatze_2': 0.0,\n",
       " 'Nate_Bargatze_TK': 42.25,\n",
       " 'Nate_Bargatze_TK_2': 20.0,\n",
       " 'Russell_Peters': 49.25,\n",
       " 'Russell_Peters_2': 60.0,\n",
       " 'Sam_Morril': 97.0,\n",
       " 'Sam_Morril_2': 25.0,\n",
       " 'Trevor_Noah': 46.0,\n",
       " 'Trevor_Noah_2': 60.333333333333336,\n",
       " 'Tom_Segura': 60.0,\n",
       " 'Tom_Segura_2': 50.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    filtered_sentence = []\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_metric(model_output, ground_truth):\n",
    "    found = {}\n",
    "\n",
    "    for index, row in model.iterrows():\n",
    "        comedian_name = row['Comedian']\n",
    "        model_output = row['Sentence']   \n",
    "        simple_model_output = simple_sentence(model_output)\n",
    "        matching = ground_truth[ground_truth['comedian'] == comedian_name]\n",
    "\n",
    "        if model_output not in found:\n",
    "            found[model_output] = [comedian_name, 0]  \n",
    "\n",
    "        for index2, row2 in matching.iterrows():\n",
    "            truth = row2['sentence']\n",
    "            simple_truth = simple_sentence(truth)\n",
    "            stop_model = remove_stop_words(simple_model_output)\n",
    "            stop_truth = remove_stop_words(simple_truth)\n",
    "            if simple_truth == simple_model_output or stop_model in stop_truth:\n",
    "                found[model_output][0] = comedian_name  \n",
    "                found[model_output][1] = 100\n",
    "            else:\n",
    "                fuzzy_score = fuzz.partial_ratio(stop_truth, stop_model)\n",
    "                if fuzzy_score > 60:\n",
    "                    found[model_output][0] = comedian_name \n",
    "                    found[model_output][1] = max(found[model_output][1], fuzzy_score)\n",
    "        \n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = base_metric(model, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(found, num_sentences):\n",
    "    correct_guesses = {}\n",
    "    \n",
    "    for val in found.values():\n",
    "        comedian_name = val[0]\n",
    "        if comedian_name not in correct_guesses:\n",
    "            correct_guesses[comedian_name] = val[1]\n",
    "        else:\n",
    "            correct_guesses[comedian_name] += val[1]\n",
    "    \n",
    "    for comedian_name, score in correct_guesses.items():\n",
    "        correct_guesses[comedian_name] = (correct_guesses[comedian_name]/num_sentences[comedian_name]) \n",
    "        \n",
    "    return correct_guesses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found, quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': 100.0,\n",
       " 'Anthony_Jeselnik_2': 66.66666666666667,\n",
       " 'Ali_Wong': 0.0,\n",
       " 'Ali_Wong_2': 66.66666666666667,\n",
       " 'Chelsea_Peretti': 33.333333333333336,\n",
       " 'Chelsea_Peretti_2': 50.0,\n",
       " 'Donald_Glover': 33.333333333333336,\n",
       " 'Donald_Glover_2': 80.66666666666667,\n",
       " 'Hasan_Minhaj': 50.0,\n",
       " 'Hasan_Minhaj_2': 50.0,\n",
       " 'Iliza_Shlesinger': 58.0,\n",
       " 'Iliza_Shlesinger_2': 50.0,\n",
       " 'Jim_Gaffigan': 87.75,\n",
       " 'Jim_Gaffigan_2': 58.666666666666664,\n",
       " 'Joe_List': 83.25,\n",
       " 'Joe_List_2': 50.0,\n",
       " 'John_Mulaney': 40.0,\n",
       " 'John_Mulaney_2': 61.25,\n",
       " 'Jimmy_Yang': 0.0,\n",
       " 'Jimmy_Yang_2': 75.0,\n",
       " 'Louis_CK': 100.0,\n",
       " 'Louis_CK_2': 65.25,\n",
       " 'Nate_Bargatze': 62.666666666666664,\n",
       " 'Nate_Bargatze_2': 33.0,\n",
       " 'Nate_Bargatze_TK': 42.5,\n",
       " 'Nate_Bargatze_TK_2': 20.0,\n",
       " 'Russell_Peters': 48.25,\n",
       " 'Russell_Peters_2': 88.6,\n",
       " 'Sam_Morril': 100.0,\n",
       " 'Sam_Morril_2': 42.5,\n",
       " 'Trevor_Noah': 45.5,\n",
       " 'Trevor_Noah_2': 61.333333333333336,\n",
       " 'Tom_Segura': 60.0,\n",
       " 'Tom_Segura_2': 50.0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = pd.read_csv('/home/ada/humor/humor/standup_transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = []\n",
    "\n",
    "for i in range(len(transcript['comedian'])):\n",
    "    comedian = transcript['comedian'][i]\n",
    "    trans = transcript['transcript'][i]\n",
    "    sentences = nltk.sent_tokenize(trans)\n",
    "    selected = random.sample(sentences, min(3, len(sentences)))\n",
    "    \n",
    "    for sentence in selected:\n",
    "        random_sentences.append({'comedian': comedian, 'sentence': sentence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedian</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>‘Cause they’re all in jail for the exact same ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>And I do not tolerate racism.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>Very racist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>Find one moment about you and your grandma you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>When I was like four years old, before I learn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             comedian                                           sentence\n",
       "0    Anthony_Jeselnik  ‘Cause they’re all in jail for the exact same ...\n",
       "1    Anthony_Jeselnik                      And I do not tolerate racism.\n",
       "2    Anthony_Jeselnik                                       Very racist.\n",
       "3  Anthony_Jeselnik_2  Find one moment about you and your grandma you...\n",
       "4  Anthony_Jeselnik_2  When I was like four years old, before I learn..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test = pd.DataFrame(random_sentences)\n",
    "base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = base_metric(model, base_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found, quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': 0.0,\n",
       " 'Anthony_Jeselnik_2': 0.0,\n",
       " 'Ali_Wong': 22.25,\n",
       " 'Ali_Wong_2': 20.666666666666668,\n",
       " 'Chelsea_Peretti': 23.0,\n",
       " 'Chelsea_Peretti_2': 66.25,\n",
       " 'Donald_Glover': 23.0,\n",
       " 'Donald_Glover_2': 62.0,\n",
       " 'Hasan_Minhaj': 25.0,\n",
       " 'Hasan_Minhaj_2': 97.25,\n",
       " 'Iliza_Shlesinger': 22.333333333333332,\n",
       " 'Iliza_Shlesinger_2': 80.0,\n",
       " 'Jim_Gaffigan': 77.75,\n",
       " 'Jim_Gaffigan_2': 25.333333333333332,\n",
       " 'Joe_List': 25.0,\n",
       " 'Joe_List_2': 0.0,\n",
       " 'John_Mulaney': 20.0,\n",
       " 'John_Mulaney_2': 36.25,\n",
       " 'Jimmy_Yang': 0.0,\n",
       " 'Jimmy_Yang_2': 0.0,\n",
       " 'Louis_CK': 52.6,\n",
       " 'Louis_CK_2': 15.25,\n",
       " 'Nate_Bargatze': 33.333333333333336,\n",
       " 'Nate_Bargatze_2': 0.0,\n",
       " 'Nate_Bargatze_TK': 42.5,\n",
       " 'Nate_Bargatze_TK_2': 20.0,\n",
       " 'Russell_Peters': 34.5,\n",
       " 'Russell_Peters_2': 40.0,\n",
       " 'Sam_Morril': 0.0,\n",
       " 'Sam_Morril_2': 0.0,\n",
       " 'Trevor_Noah': 100.0,\n",
       " 'Trevor_Noah_2': 26.0,\n",
       " 'Tom_Segura': 27.4,\n",
       " 'Tom_Segura_2': 50.0}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
