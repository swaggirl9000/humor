{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic comparison of simply comparing how many of the sentences the model got correct in terms of the extracted ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv('/home/ada/humor/standup_data.csv')\n",
    "model = pd.read_csv('/home/ada/humor/humor/gemma_answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['comedian', 'laugh_start', 'laugh_end', 'sentence'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedian</th>\n",
       "      <th>laugh_start</th>\n",
       "      <th>laugh_end</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>17.268</td>\n",
       "      <td>19.352</td>\n",
       "      <td>He wasn't crying. Just tears, he was giving me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>32.292</td>\n",
       "      <td>34.182</td>\n",
       "      <td>He would... The sweetest thing he was allowed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>38.790</td>\n",
       "      <td>41.441</td>\n",
       "      <td>He was just allowed to have mints. So he would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>44.903</td>\n",
       "      <td>53.441</td>\n",
       "      <td>So his breath was so fresh... the vapors from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>68.880</td>\n",
       "      <td>73.824</td>\n",
       "      <td>And I would take him to the park and I was the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        comedian  laugh_start  laugh_end  \\\n",
       "0  Donald_Glover       17.268     19.352   \n",
       "1  Donald_Glover       32.292     34.182   \n",
       "2  Donald_Glover       38.790     41.441   \n",
       "3  Donald_Glover       44.903     53.441   \n",
       "4  Donald_Glover       68.880     73.824   \n",
       "\n",
       "                                            sentence  \n",
       "0  He wasn't crying. Just tears, he was giving me...  \n",
       "1  He would... The sweetest thing he was allowed ...  \n",
       "2  He was just allowed to have mints. So he would...  \n",
       "3  So his breath was so fresh... the vapors from ...  \n",
       "4  And I would take him to the park and I was the...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comedian</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>My mom actually should've been on one of the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>When I was a kid, like nine years old, I'd com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>I've never talked to a group of people without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>And I know my grandma loved it too, because it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Comedian                                           Sentence\n",
       "0    Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...\n",
       "1    Anthony_Jeselnik  My mom actually should've been on one of the p...\n",
       "2    Anthony_Jeselnik  When I was a kid, like nine years old, I'd com...\n",
       "3  Anthony_Jeselnik_2  I've never talked to a group of people without...\n",
       "4  Anthony_Jeselnik_2  And I know my grandma loved it too, because it..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's calculate the score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, simplify the sentences by changing them to all lowercase and removing punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def simple_sentence(sentence):\n",
    "    cleaned_sentence = sentence.lower()\n",
    "    cleaned_sentence = re.sub(r'[^\\w\\s]', '', cleaned_sentence)\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the score by first checking if the string matches entirely or is in the ground truth. If this is not the case, move onto fuzzy string matching to see the similarity of the responses. If the score is above 50%, we can add this to the total score. The score is the average of correct responses per transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = {}\n",
    "\n",
    "for index, row in ground_truth.iterrows():\n",
    "    comedian_name = row['comedian']\n",
    "    truth = row['sentence']   \n",
    "    simple_truth = simple_sentence(truth)\n",
    "    matching_rows = model[model['Comedian'] == comedian_name]\n",
    "    \n",
    "    score = 0\n",
    "    num_sentences = set()\n",
    "\n",
    "    if truth not in found:\n",
    "        found[truth] = [comedian_name, False, score, 0]  \n",
    "\n",
    "    for index2, row2 in matching_rows.iterrows():\n",
    "        model_answer = row2['Sentence']      \n",
    "        simple_model_answer = simple_sentence(model_answer)\n",
    "        num_sentences.add(model_answer)\n",
    "        \n",
    "        if simple_truth == simple_model_answer or simple_model_answer in simple_truth:\n",
    "            score = 100 \n",
    "            found[truth][0] = comedian_name  \n",
    "            found[truth][1] = True \n",
    "            found[truth][2] = score\n",
    "        else:\n",
    "            fuzzy_score = fuzz.partial_ratio(simple_truth, simple_model_answer)\n",
    "            if fuzzy_score > 60:\n",
    "                found[truth][0] = comedian_name \n",
    "                found[truth][1] = True\n",
    "                if fuzzy_score >  found[truth][2]:\n",
    "                    found[truth][2] = fuzzy_score\n",
    "    found[truth][3] = len(num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(found):\n",
    "    correct_guesses = {}\n",
    "    num_sentences = {}\n",
    "    \n",
    "    for val in found.values():\n",
    "        comedian_name = val[0]\n",
    "        number_of_sentences = val[3]\n",
    "        if comedian_name not in correct_guesses:\n",
    "            correct_guesses[comedian_name] = val[2]\n",
    "            num_sentences[comedian_name] = number_of_sentences\n",
    "        else:\n",
    "            correct_guesses[comedian_name] += val[2]\n",
    "    \n",
    "    for comedian_name, score in correct_guesses.items():\n",
    "        correct_guesses[comedian_name] = (correct_guesses[comedian_name]/num_sentences[comedian_name]) \n",
    "        \n",
    "    return correct_guesses \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Donald_Glover': 51.333333333333336,\n",
       " 'Donald_Glover_2': 126.66666666666667,\n",
       " 'Anthony_Jeselnik': 100.0,\n",
       " 'Anthony_Jeselnik_2': 66.0,\n",
       " 'Chelsea_Peretti': 110.33333333333333,\n",
       " 'Chelsea_Peretti_2': 50.0,\n",
       " 'Louis_CK': 106.8,\n",
       " 'Louis_CK_2': 50.0,\n",
       " 'John_Mulaney': 103.8,\n",
       " 'John_Mulaney_2': 42.75,\n",
       " 'Ali_Wong': 25.0,\n",
       " 'Ali_Wong_2': 66.66666666666667,\n",
       " 'Hasan_Minhaj': 91.5,\n",
       " 'Hasan_Minhaj_2': 25.0,\n",
       " 'Iliza_Shlesinger': 90.0,\n",
       " 'Iliza_Shlesinger_2': 50.0,\n",
       " 'Jim_Gaffigan': 82.25,\n",
       " 'Jim_Gaffigan_2': 79.33333333333333,\n",
       " 'Joe_List': 50.0,\n",
       " 'Joe_List_2': 25.0,\n",
       " 'Jimmy_Yang': 50.0,\n",
       " 'Jimmy_Yang_2': 75.0,\n",
       " 'Nate_Bargatze': 60.333333333333336,\n",
       " 'Nate_Bargatze_2': 15.25,\n",
       " 'Nate_Bargatze_TK': 99.5,\n",
       " 'Nate_Bargatze_TK_2': 20.0,\n",
       " 'Russell_Peters': 74.25,\n",
       " 'Russell_Peters_2': 76.4,\n",
       " 'Sam_Morril': 97.0,\n",
       " 'Sam_Morril_2': 41.5,\n",
       " 'Trevor_Noah': 46.0,\n",
       " 'Trevor_Noah_2': 115.33333333333333,\n",
       " 'Tom_Segura': 73.4,\n",
       " 'Tom_Segura_2': 150.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start from the model to avoid duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anthony_Jeselnik': 3, 'Anthony_Jeselnik_2': 3, 'Ali_Wong': 4, 'Ali_Wong_2': 3, 'Chelsea_Peretti': 3, 'Chelsea_Peretti_2': 4, 'Donald_Glover': 3, 'Donald_Glover_2': 3, 'Hasan_Minhaj': 4, 'Hasan_Minhaj_2': 4, 'Iliza_Shlesinger': 3, 'Iliza_Shlesinger_2': 2, 'Jim_Gaffigan': 4, 'Jim_Gaffigan_2': 3, 'Joe_List': 4, 'Joe_List_2': 4, 'John_Mulaney': 5, 'John_Mulaney_2': 4, 'Jimmy_Yang': 2, 'Jimmy_Yang_2': 4, 'Louis_CK': 5, 'Louis_CK_2': 4, 'Nate_Bargatze': 3, 'Nate_Bargatze_2': 4, 'Nate_Bargatze_TK': 4, 'Nate_Bargatze_TK_2': 5, 'Russell_Peters': 4, 'Russell_Peters_2': 5, 'Sam_Morril': 2, 'Sam_Morril_2': 4, 'Trevor_Noah': 2, 'Trevor_Noah_2': 3, 'Tom_Segura': 5, 'Tom_Segura_2': 2}\n"
     ]
    }
   ],
   "source": [
    "quotes_count_dict = {}\n",
    "for comedian in model['Comedian']:\n",
    "    if comedian in quotes_count_dict:\n",
    "        quotes_count_dict[comedian] += 1\n",
    "    else:\n",
    "        quotes_count_dict[comedian] = 1\n",
    "\n",
    "print(quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = {}\n",
    "\n",
    "for index, row in model.iterrows():\n",
    "    comedian_name = row['Comedian']\n",
    "    model_output = row['Sentence']   \n",
    "    simple_model_output = simple_sentence(model_output)\n",
    "    matching = ground_truth[ground_truth['comedian'] == comedian_name]\n",
    "\n",
    "    if truth not in found:\n",
    "        found[model_output] = [comedian_name, 0]  \n",
    "\n",
    "    for index2, row2 in matching.iterrows():\n",
    "        truth = row2['sentence']\n",
    "        simple_truth = simple_sentence(truth)\n",
    "\n",
    "        if simple_truth == simple_model_output or simple_model_output in simple_truth:\n",
    "            found[model_output][0] = comedian_name  \n",
    "            found[model_output][1] = 100\n",
    "        else:\n",
    "            fuzzy_score = fuzz.partial_ratio(simple_truth, simple_model_output)\n",
    "            if fuzzy_score > 60:\n",
    "                found[model_output][0] = comedian_name \n",
    "                found[model_output][1] = max(found[model_output][1], fuzzy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(found, num_sentences):\n",
    "    correct_guesses = {}\n",
    "    \n",
    "    for val in found.values():\n",
    "        comedian_name = val[0]\n",
    "        if comedian_name not in correct_guesses:\n",
    "            correct_guesses[comedian_name] = val[1]\n",
    "        else:\n",
    "            correct_guesses[comedian_name] += val[1]\n",
    "    \n",
    "    for comedian_name, score in correct_guesses.items():\n",
    "        correct_guesses[comedian_name] = (correct_guesses[comedian_name]/num_sentences[comedian_name]) \n",
    "        \n",
    "    return correct_guesses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found, quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': 100.0,\n",
       " 'Anthony_Jeselnik_2': 66.0,\n",
       " 'Ali_Wong': 42.25,\n",
       " 'Ali_Wong_2': 66.66666666666667,\n",
       " 'Chelsea_Peretti': 56.333333333333336,\n",
       " 'Chelsea_Peretti_2': 50.0,\n",
       " 'Donald_Glover': 30.333333333333332,\n",
       " 'Donald_Glover_2': 82.66666666666667,\n",
       " 'Hasan_Minhaj': 75.0,\n",
       " 'Hasan_Minhaj_2': 50.0,\n",
       " 'Iliza_Shlesinger': 66.66666666666667,\n",
       " 'Iliza_Shlesinger_2': 81.0,\n",
       " 'Jim_Gaffigan': 87.25,\n",
       " 'Jim_Gaffigan_2': 54.0,\n",
       " 'Joe_List': 67.25,\n",
       " 'Joe_List_2': 25.0,\n",
       " 'John_Mulaney': 77.0,\n",
       " 'John_Mulaney_2': 42.75,\n",
       " 'Jimmy_Yang': 50.0,\n",
       " 'Jimmy_Yang_2': 75.0,\n",
       " 'Louis_CK': 100.0,\n",
       " 'Louis_CK_2': 65.25,\n",
       " 'Nate_Bargatze': 60.333333333333336,\n",
       " 'Nate_Bargatze_2': 15.25,\n",
       " 'Nate_Bargatze_TK': 99.5,\n",
       " 'Nate_Bargatze_TK_2': 20.0,\n",
       " 'Russell_Peters': 74.25,\n",
       " 'Russell_Peters_2': 60.0,\n",
       " 'Sam_Morril': 97.0,\n",
       " 'Sam_Morril_2': 25.0,\n",
       " 'Trevor_Noah': 46.0,\n",
       " 'Trevor_Noah_2': 93.66666666666667,\n",
       " 'Tom_Segura': 73.4,\n",
       " 'Tom_Segura_2': 50.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    filtered_sentence = []\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_metric(model_output, ground_truth):\n",
    "    found = {}\n",
    "\n",
    "    for index, row in model.iterrows():\n",
    "        comedian_name = row['Comedian']\n",
    "        model_output = row['Sentence']   \n",
    "        simple_model_output = simple_sentence(model_output)\n",
    "        matching = ground_truth[ground_truth['comedian'] == comedian_name]\n",
    "\n",
    "        if model_output not in found:\n",
    "            found[model_output] = [comedian_name, 0]  \n",
    "\n",
    "        for index2, row2 in matching.iterrows():\n",
    "            truth = row2['sentence']\n",
    "            simple_truth = simple_sentence(truth)\n",
    "            stop_model = remove_stop_words(simple_model_output)\n",
    "            stop_truth = remove_stop_words(simple_truth)\n",
    "            if simple_truth == simple_model_output or stop_model in stop_truth:\n",
    "                found[model_output][0] = comedian_name  \n",
    "                found[model_output][1] = 100\n",
    "            else:\n",
    "                fuzzy_score = fuzz.partial_ratio(stop_truth, stop_model)\n",
    "                if fuzzy_score > 60:\n",
    "                    found[model_output][0] = comedian_name \n",
    "                    found[model_output][1] = max(found[model_output][1], fuzzy_score)\n",
    "        \n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = base_metric(model, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(found, num_sentences):\n",
    "    correct_guesses = {}\n",
    "    \n",
    "    for val in found.values():\n",
    "        comedian_name = val[0]\n",
    "        if comedian_name not in correct_guesses:\n",
    "            correct_guesses[comedian_name] = val[1]\n",
    "        else:\n",
    "            correct_guesses[comedian_name] += val[1]\n",
    "    \n",
    "    for comedian_name, score in correct_guesses.items():\n",
    "        correct_guesses[comedian_name] = (correct_guesses[comedian_name]/num_sentences[comedian_name]) \n",
    "        \n",
    "    return correct_guesses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found, quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': 100.0,\n",
       " 'Anthony_Jeselnik_2': 66.66666666666667,\n",
       " 'Ali_Wong': 42.0,\n",
       " 'Ali_Wong_2': 66.66666666666667,\n",
       " 'Chelsea_Peretti': 33.333333333333336,\n",
       " 'Chelsea_Peretti_2': 50.0,\n",
       " 'Donald_Glover': 30.0,\n",
       " 'Donald_Glover_2': 80.66666666666667,\n",
       " 'Hasan_Minhaj': 75.0,\n",
       " 'Hasan_Minhaj_2': 50.0,\n",
       " 'Iliza_Shlesinger': 66.66666666666667,\n",
       " 'Iliza_Shlesinger_2': 50.0,\n",
       " 'Jim_Gaffigan': 87.75,\n",
       " 'Jim_Gaffigan_2': 55.333333333333336,\n",
       " 'Joe_List': 83.25,\n",
       " 'Joe_List_2': 25.0,\n",
       " 'John_Mulaney': 78.4,\n",
       " 'John_Mulaney_2': 61.25,\n",
       " 'Jimmy_Yang': 50.0,\n",
       " 'Jimmy_Yang_2': 75.0,\n",
       " 'Louis_CK': 100.0,\n",
       " 'Louis_CK_2': 65.25,\n",
       " 'Nate_Bargatze': 62.666666666666664,\n",
       " 'Nate_Bargatze_2': 33.0,\n",
       " 'Nate_Bargatze_TK': 99.0,\n",
       " 'Nate_Bargatze_TK_2': 20.0,\n",
       " 'Russell_Peters': 72.5,\n",
       " 'Russell_Peters_2': 88.6,\n",
       " 'Sam_Morril': 100.0,\n",
       " 'Sam_Morril_2': 42.5,\n",
       " 'Trevor_Noah': 45.5,\n",
       " 'Trevor_Noah_2': 94.66666666666667,\n",
       " 'Tom_Segura': 60.0,\n",
       " 'Tom_Segura_2': 50.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = pd.read_csv('/home/ada/humor/humor/standup_transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = []\n",
    "\n",
    "for i in range(len(transcript['comedian'])):\n",
    "    comedian = transcript['comedian'][i]\n",
    "    trans = transcript['transcript'][i]\n",
    "    sentences = nltk.sent_tokenize(trans)\n",
    "    selected = random.sample(sentences, min(3, len(sentences)))\n",
    "    \n",
    "    for sentence in selected:\n",
    "        random_sentences.append({'comedian': comedian, 'sentence': sentence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedian</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>That’s ignorance and I hate that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>She was my mom, of course I loved her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>Of course this was before 9/11 so… my bad, eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>Try not to.” So I walked up and was like, “You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>Was like, “I’ve never talked to a group of peo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             comedian                                           sentence\n",
       "0    Anthony_Jeselnik                  That’s ignorance and I hate that.\n",
       "1    Anthony_Jeselnik             She was my mom, of course I loved her.\n",
       "2    Anthony_Jeselnik  Of course this was before 9/11 so… my bad, eve...\n",
       "3  Anthony_Jeselnik_2  Try not to.” So I walked up and was like, “You...\n",
       "4  Anthony_Jeselnik_2  Was like, “I’ve never talked to a group of peo..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test = pd.DataFrame(random_sentences)\n",
    "base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedian</th>\n",
       "      <th>sentence</th>\n",
       "      <th>no_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>That’s ignorance and I hate that.</td>\n",
       "      <td>That ’ ignorance I hate .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>She was my mom, of course I loved her.</td>\n",
       "      <td>She mom , course I loved .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>Of course this was before 9/11 so… my bad, eve...</td>\n",
       "      <td>Of course 9/11 so… bad , everybody .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>Try not to.” So I walked up and was like, “You...</td>\n",
       "      <td>Try to. ” So I walked like , “ You know favori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>Was like, “I’ve never talked to a group of peo...</td>\n",
       "      <td>Was like , “ I ’ never talked group people wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Tom_Segura</td>\n",
       "      <td>Cool.” And he goes, “We just need to go get it...</td>\n",
       "      <td>Cool. ” And goes , “ We need go get it. ” I li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tom_Segura</td>\n",
       "      <td>Paralysis.</td>\n",
       "      <td>Paralysis .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Tom_Segura_2</td>\n",
       "      <td>You’re like, “I’m in trouble.” It’s always som...</td>\n",
       "      <td>You ’ like , “ I ’ trouble. ” It ’ always lady...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Tom_Segura_2</td>\n",
       "      <td>It felt like the inside of my body hugged the ...</td>\n",
       "      <td>It felt like inside body hugged outside body ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Tom_Segura_2</td>\n",
       "      <td>There’s “Hold Open,” and “Close.” And you can ...</td>\n",
       "      <td>There ’ “ Hold Open , ” “ Close. ” And watch p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               comedian                                           sentence  \\\n",
       "0      Anthony_Jeselnik                  That’s ignorance and I hate that.   \n",
       "1      Anthony_Jeselnik             She was my mom, of course I loved her.   \n",
       "2      Anthony_Jeselnik  Of course this was before 9/11 so… my bad, eve...   \n",
       "3    Anthony_Jeselnik_2  Try not to.” So I walked up and was like, “You...   \n",
       "4    Anthony_Jeselnik_2  Was like, “I’ve never talked to a group of peo...   \n",
       "..                  ...                                                ...   \n",
       "97           Tom_Segura  Cool.” And he goes, “We just need to go get it...   \n",
       "98           Tom_Segura                                         Paralysis.   \n",
       "99         Tom_Segura_2  You’re like, “I’m in trouble.” It’s always som...   \n",
       "100        Tom_Segura_2  It felt like the inside of my body hugged the ...   \n",
       "101        Tom_Segura_2  There’s “Hold Open,” and “Close.” And you can ...   \n",
       "\n",
       "                                               no_stop  \n",
       "0                            That ’ ignorance I hate .  \n",
       "1                           She mom , course I loved .  \n",
       "2                 Of course 9/11 so… bad , everybody .  \n",
       "3    Try to. ” So I walked like , “ You know favori...  \n",
       "4    Was like , “ I ’ never talked group people wit...  \n",
       "..                                                 ...  \n",
       "97   Cool. ” And goes , “ We need go get it. ” I li...  \n",
       "98                                         Paralysis .  \n",
       "99   You ’ like , “ I ’ trouble. ” It ’ always lady...  \n",
       "100  It felt like inside body hugged outside body ,...  \n",
       "101  There ’ “ Hold Open , ” “ Close. ” And watch p...  \n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Donald_Glover\n",
      "1      Donald_Glover\n",
      "2      Donald_Glover\n",
      "3      Donald_Glover\n",
      "4      Donald_Glover\n",
      "           ...      \n",
      "241       Tom_Segura\n",
      "242       Tom_Segura\n",
      "243     Tom_Segura_2\n",
      "244     Tom_Segura_2\n",
      "245     Tom_Segura_2\n",
      "Name: comedian, Length: 246, dtype: object\n",
      "0      17.2680\n",
      "1      32.2920\n",
      "2      38.7900\n",
      "3      44.9030\n",
      "4      68.8800\n",
      "        ...   \n",
      "241    56.5030\n",
      "242    61.4021\n",
      "243    44.7760\n",
      "244    50.7880\n",
      "245    58.9700\n",
      "Name: laugh_start, Length: 246, dtype: float64\n",
      "0      19.352\n",
      "1      34.182\n",
      "2      41.441\n",
      "3      53.441\n",
      "4      73.824\n",
      "        ...  \n",
      "241    58.176\n",
      "242    63.451\n",
      "243    47.440\n",
      "244    53.995\n",
      "245    60.597\n",
      "Name: laugh_end, Length: 246, dtype: float64\n",
      "0      He wasn't crying. Just tears, he was giving me...\n",
      "1      He would... The sweetest thing he was allowed ...\n",
      "2      He was just allowed to have mints. So he would...\n",
      "3      So his breath was so fresh... the vapors from ...\n",
      "4      And I would take him to the park and I was the...\n",
      "                             ...                        \n",
      "241           Anybody comes in here, blast 'em.\" Inside?\n",
      "242    Paralysis. But what I said was, \"That's what's...\n",
      "243    And you can watch people walk up and be like, ...\n",
      "244        And then you see it close, and you're like...\n",
      "245    Sometimes, a second later it opens, and you're...\n",
      "Name: sentence, Length: 246, dtype: object\n",
      "0      He n't crying . Just tears , giving mean mug ,...\n",
      "1        He would ... The sweetest thing allowed mints .\n",
      "2      He allowed mints . So would steal mints handful .\n",
      "3      So breath fresh ... vapors mouth made eyes wat...\n",
      "4      And I would take park I boy , know , I hanging...\n",
      "                             ...                        \n",
      "241              Anybody comes , blast 'em . '' Inside ?\n",
      "242          Paralysis . But I said , `` That 's 's . ''\n",
      "243    And watch people walk like , `` Mm-mm . '' -An...\n",
      "244                         And see close , 're like ...\n",
      "245    Sometimes , second later opens , 're like , ``...\n",
      "Name: no_stop, Length: 246, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "comedian       None\n",
       "laugh_start    None\n",
       "laugh_end      None\n",
       "sentence       None\n",
       "no_stop        None\n",
       "dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth.apply(lambda row: print(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedian</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>My mom actually should've been on one of the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>When I was a kid, like nine years old, I'd com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>I've never talked to a group of people without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>And I know my grandma loved it too, because it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Tom_Segura</td>\n",
       "      <td>I'll go get it. You stay here and watch my place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Tom_Segura</td>\n",
       "      <td>That's what's up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Tom_Segura</td>\n",
       "      <td>Can we get a description before we agree to te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Tom_Segura_2</td>\n",
       "      <td>I got such a warm rush through my body. It fel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Tom_Segura_2</td>\n",
       "      <td>There's “Hold Open,” and “Close.” And you can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               comedian                                           sentence\n",
       "0      Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...\n",
       "1      Anthony_Jeselnik  My mom actually should've been on one of the p...\n",
       "2      Anthony_Jeselnik  When I was a kid, like nine years old, I'd com...\n",
       "3    Anthony_Jeselnik_2  I've never talked to a group of people without...\n",
       "4    Anthony_Jeselnik_2  And I know my grandma loved it too, because it...\n",
       "..                  ...                                                ...\n",
       "116          Tom_Segura  I'll go get it. You stay here and watch my place.\n",
       "117          Tom_Segura                                  That's what's up.\n",
       "118          Tom_Segura  Can we get a description before we agree to te...\n",
       "119        Tom_Segura_2  I got such a warm rush through my body. It fel...\n",
       "120        Tom_Segura_2  There's “Hold Open,” and “Close.” And you can ...\n",
       "\n",
       "[121 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.columns = [c.lower() for c in model.columns]\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08472222222222221"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_answers = model\n",
    "\n",
    "scores = model_answers.apply(\n",
    "    lambda row_model: ground_truth.apply(\n",
    "        lambda row_truth: \n",
    "            fuzz.ratio(row_truth[\"sentence\"], row_model[\"sentence\"]) \n",
    "            if row_model[\"comedian\"] == row_truth[\"comedian\"] \n",
    "            else None,\n",
    "    axis=1),\n",
    "axis=1) \\\n",
    "    .sub(60) \\\n",
    "    .clip(lower=0) \\\n",
    "    .div(100 - 60) \\\n",
    "    .melt(ignore_index=False) \\\n",
    "    .dropna() \\\n",
    "    .reset_index() \\\n",
    "    .join(model_answers[\"sentence\"], on=\"index\") \\\n",
    "    .rename(columns={\"sentence\": \"model\"}) \\\n",
    "    .join(ground_truth, on=\"variable\") \\\n",
    "    .rename(columns={\"sentence\": \"truth\", \"value\": \"score\"})\n",
    "    \n",
    "scores = scores[[\"comedian\", \"model\", \"truth\", \"score\"]]\n",
    "\n",
    "scores.groupby(\"comedian\")[\"score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paralysis. But what I said was, \"That\\'s what\\'s up.\"'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ground_truth.loc[242, \"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paralysis.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test.loc[98, \"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m found \u001b[38;5;241m=\u001b[39m \u001b[43mbase_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m, in \u001b[0;36mbase_metric\u001b[0;34m(model_output, ground_truth)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbase_metric\u001b[39m(model_output, ground_truth):\n\u001b[1;32m      2\u001b[0m     found \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      5\u001b[0m         comedian_name \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComedian\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m         model_output \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentence\u001b[39m\u001b[38;5;124m'\u001b[39m]   \n",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m, in \u001b[0;36mbase_metric\u001b[0;34m(model_output, ground_truth)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbase_metric\u001b[39m(model_output, ground_truth):\n\u001b[1;32m      2\u001b[0m     found \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      5\u001b[0m         comedian_name \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComedian\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m         model_output \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentence\u001b[39m\u001b[38;5;124m'\u001b[39m]   \n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/humor/.venv/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "found = base_metric(base_test, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found, quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That’s ignorance and I hate that.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test.loc[0, \"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedian</th>\n",
       "      <th>laugh_start</th>\n",
       "      <th>laugh_end</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>16.898</td>\n",
       "      <td>19.405</td>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>29.085</td>\n",
       "      <td>31.100</td>\n",
       "      <td>Sold my passport on the street for 300 bucks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>34.874</td>\n",
       "      <td>36.233</td>\n",
       "      <td>Weird joke to clap for, but sure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>43.756</td>\n",
       "      <td>48.912</td>\n",
       "      <td>My mom actually should've been on one of the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>86.505</td>\n",
       "      <td>88.497</td>\n",
       "      <td>And when I did that, my mom would act weird. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>93.982</td>\n",
       "      <td>100.708</td>\n",
       "      <td>And I would say, \"Shut up, Mom, that's racist....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>114.653</td>\n",
       "      <td>120.278</td>\n",
       "      <td>And we never talk, write letters or any of tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            comedian  laugh_start  laugh_end  \\\n",
       "17  Anthony_Jeselnik       16.898     19.405   \n",
       "18  Anthony_Jeselnik       29.085     31.100   \n",
       "19  Anthony_Jeselnik       34.874     36.233   \n",
       "20  Anthony_Jeselnik       43.756     48.912   \n",
       "21  Anthony_Jeselnik       86.505     88.497   \n",
       "22  Anthony_Jeselnik       93.982    100.708   \n",
       "23  Anthony_Jeselnik      114.653    120.278   \n",
       "\n",
       "                                             sentence  \n",
       "17  When I was a kid, I used to fantasize about ge...  \n",
       "18  Sold my passport on the street for 300 bucks t...  \n",
       "19                  Weird joke to clap for, but sure.  \n",
       "20  My mom actually should've been on one of the p...  \n",
       "21  And when I did that, my mom would act weird. S...  \n",
       "22  And I would say, \"Shut up, Mom, that's racist....  \n",
       "23  And we never talk, write letters or any of tha...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[ground_truth.comedian == \"Anthony_Jeselnik\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': 100.0,\n",
       " 'Anthony_Jeselnik_2': 66.66666666666667,\n",
       " 'Ali_Wong': 42.0,\n",
       " 'Ali_Wong_2': 66.66666666666667,\n",
       " 'Chelsea_Peretti': 33.333333333333336,\n",
       " 'Chelsea_Peretti_2': 50.0,\n",
       " 'Donald_Glover': 30.0,\n",
       " 'Donald_Glover_2': 80.66666666666667,\n",
       " 'Hasan_Minhaj': 75.0,\n",
       " 'Hasan_Minhaj_2': 50.0,\n",
       " 'Iliza_Shlesinger': 66.66666666666667,\n",
       " 'Iliza_Shlesinger_2': 50.0,\n",
       " 'Jim_Gaffigan': 87.75,\n",
       " 'Jim_Gaffigan_2': 55.333333333333336,\n",
       " 'Joe_List': 83.25,\n",
       " 'Joe_List_2': 25.0,\n",
       " 'John_Mulaney': 78.4,\n",
       " 'John_Mulaney_2': 61.25,\n",
       " 'Jimmy_Yang': 50.0,\n",
       " 'Jimmy_Yang_2': 75.0,\n",
       " 'Louis_CK': 100.0,\n",
       " 'Louis_CK_2': 65.25,\n",
       " 'Nate_Bargatze': 62.666666666666664,\n",
       " 'Nate_Bargatze_2': 33.0,\n",
       " 'Nate_Bargatze_TK': 99.0,\n",
       " 'Nate_Bargatze_TK_2': 20.0,\n",
       " 'Russell_Peters': 72.5,\n",
       " 'Russell_Peters_2': 88.6,\n",
       " 'Sam_Morril': 100.0,\n",
       " 'Sam_Morril_2': 42.5,\n",
       " 'Trevor_Noah': 45.5,\n",
       " 'Trevor_Noah_2': 94.66666666666667,\n",
       " 'Tom_Segura': 60.0,\n",
       " 'Tom_Segura_2': 50.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.22058823529412\n"
     ]
    }
   ],
   "source": [
    "print(sum(correct_guesses.values())/len(correct_guesses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
