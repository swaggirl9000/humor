{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic comparison of simply comparing how many of the sentences the model got correct in terms of the extracted ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv('/home/ada/humor/standup_data.csv')\n",
    "model = pd.read_csv('/home/ada/humor/humor/gemma_answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['comedian', 'laugh_start', 'laugh_end', 'sentence'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedian</th>\n",
       "      <th>laugh_start</th>\n",
       "      <th>laugh_end</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>17.268</td>\n",
       "      <td>19.352</td>\n",
       "      <td>He wasn't crying. Just tears, he was giving me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>32.292</td>\n",
       "      <td>34.182</td>\n",
       "      <td>He would... The sweetest thing he was allowed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>38.790</td>\n",
       "      <td>41.441</td>\n",
       "      <td>He was just allowed to have mints. So he would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>44.903</td>\n",
       "      <td>53.441</td>\n",
       "      <td>So his breath was so fresh... the vapors from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald_Glover</td>\n",
       "      <td>68.880</td>\n",
       "      <td>73.824</td>\n",
       "      <td>And I would take him to the park and I was the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        comedian  laugh_start  laugh_end  \\\n",
       "0  Donald_Glover       17.268     19.352   \n",
       "1  Donald_Glover       32.292     34.182   \n",
       "2  Donald_Glover       38.790     41.441   \n",
       "3  Donald_Glover       44.903     53.441   \n",
       "4  Donald_Glover       68.880     73.824   \n",
       "\n",
       "                                            sentence  \n",
       "0  He wasn't crying. Just tears, he was giving me...  \n",
       "1  He would... The sweetest thing he was allowed ...  \n",
       "2  He was just allowed to have mints. So he would...  \n",
       "3  So his breath was so fresh... the vapors from ...  \n",
       "4  And I would take him to the park and I was the...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comedian</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>When I was a kid, I used to fantasize about ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>My mom actually should've been on one of the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>When I was a kid, like nine years old, I'd com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>I've never talked to a group of people without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>And I know my grandma loved it too, because it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Comedian                                           Sentence\n",
       "0    Anthony_Jeselnik  When I was a kid, I used to fantasize about ge...\n",
       "1    Anthony_Jeselnik  My mom actually should've been on one of the p...\n",
       "2    Anthony_Jeselnik  When I was a kid, like nine years old, I'd com...\n",
       "3  Anthony_Jeselnik_2  I've never talked to a group of people without...\n",
       "4  Anthony_Jeselnik_2  And I know my grandma loved it too, because it..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's calculate the score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, simplify the sentences by changing them to all lowercase and removing punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def simple_sentence(sentence):\n",
    "    cleaned_sentence = sentence.lower()\n",
    "    cleaned_sentence = re.sub(r'[^\\w\\s]', '', cleaned_sentence)\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the score by first checking if the string matches entirely or is in the ground truth. If this is not the case, move onto fuzzy string matching to see the similarity of the responses. If the score is above 50%, we can add this to the total score. The score is the average of correct responses per transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = {}\n",
    "\n",
    "for index, row in ground_truth.iterrows():\n",
    "    comedian_name = row['comedian']\n",
    "    truth = row['sentence']   \n",
    "    simple_truth = simple_sentence(truth)\n",
    "    matching_rows = model[model['Comedian'] == comedian_name]\n",
    "    \n",
    "    score = 0\n",
    "    num_sentences = set()\n",
    "\n",
    "    if truth not in found:\n",
    "        found[truth] = [comedian_name, False, score, 0]  \n",
    "\n",
    "    for index2, row2 in matching_rows.iterrows():\n",
    "        model_answer = row2['Sentence']      \n",
    "        simple_model_answer = simple_sentence(model_answer)\n",
    "        num_sentences.add(model_answer)\n",
    "        \n",
    "        if simple_truth == simple_model_answer or simple_model_answer in simple_truth:\n",
    "            score = 100 \n",
    "            found[truth][0] = comedian_name  \n",
    "            found[truth][1] = True \n",
    "            found[truth][2] = score\n",
    "        else:\n",
    "            fuzzy_score = fuzz.partial_ratio(simple_truth, simple_model_answer)\n",
    "            if fuzzy_score > 60:\n",
    "                found[truth][0] = comedian_name \n",
    "                found[truth][1] = True\n",
    "                if fuzzy_score >  found[truth][2]:\n",
    "                    found[truth][2] = fuzzy_score\n",
    "    found[truth][3] = len(num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(found):\n",
    "    correct_guesses = {}\n",
    "    num_sentences = {}\n",
    "    \n",
    "    for val in found.values():\n",
    "        comedian_name = val[0]\n",
    "        number_of_sentences = val[3]\n",
    "        if comedian_name not in correct_guesses:\n",
    "            correct_guesses[comedian_name] = val[2]\n",
    "            num_sentences[comedian_name] = number_of_sentences\n",
    "        else:\n",
    "            correct_guesses[comedian_name] += val[2]\n",
    "    \n",
    "    for comedian_name, score in correct_guesses.items():\n",
    "        correct_guesses[comedian_name] = (correct_guesses[comedian_name]/num_sentences[comedian_name]) \n",
    "        \n",
    "    return correct_guesses \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Donald_Glover': 51.333333333333336,\n",
       " 'Donald_Glover_2': 126.66666666666667,\n",
       " 'Anthony_Jeselnik': 100.0,\n",
       " 'Anthony_Jeselnik_2': 66.0,\n",
       " 'Chelsea_Peretti': 110.33333333333333,\n",
       " 'Chelsea_Peretti_2': 50.0,\n",
       " 'Louis_CK': 106.8,\n",
       " 'Louis_CK_2': 50.0,\n",
       " 'John_Mulaney': 103.8,\n",
       " 'John_Mulaney_2': 42.75,\n",
       " 'Ali_Wong': 25.0,\n",
       " 'Ali_Wong_2': 66.66666666666667,\n",
       " 'Hasan_Minhaj': 91.5,\n",
       " 'Hasan_Minhaj_2': 25.0,\n",
       " 'Iliza_Shlesinger': 90.0,\n",
       " 'Iliza_Shlesinger_2': 50.0,\n",
       " 'Jim_Gaffigan': 82.25,\n",
       " 'Jim_Gaffigan_2': 79.33333333333333,\n",
       " 'Joe_List': 50.0,\n",
       " 'Joe_List_2': 25.0,\n",
       " 'Jimmy_Yang': 50.0,\n",
       " 'Jimmy_Yang_2': 75.0,\n",
       " 'Nate_Bargatze': 60.333333333333336,\n",
       " 'Nate_Bargatze_2': 15.25,\n",
       " 'Nate_Bargatze_TK': 99.5,\n",
       " 'Nate_Bargatze_TK_2': 20.0,\n",
       " 'Russell_Peters': 74.25,\n",
       " 'Russell_Peters_2': 76.4,\n",
       " 'Sam_Morril': 97.0,\n",
       " 'Sam_Morril_2': 41.5,\n",
       " 'Trevor_Noah': 46.0,\n",
       " 'Trevor_Noah_2': 115.33333333333333,\n",
       " 'Tom_Segura': 73.4,\n",
       " 'Tom_Segura_2': 150.0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start from the model to avoid duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anthony_Jeselnik': 3, 'Anthony_Jeselnik_2': 3, 'Ali_Wong': 4, 'Ali_Wong_2': 3, 'Chelsea_Peretti': 3, 'Chelsea_Peretti_2': 4, 'Donald_Glover': 3, 'Donald_Glover_2': 3, 'Hasan_Minhaj': 4, 'Hasan_Minhaj_2': 4, 'Iliza_Shlesinger': 3, 'Iliza_Shlesinger_2': 2, 'Jim_Gaffigan': 4, 'Jim_Gaffigan_2': 3, 'Joe_List': 4, 'Joe_List_2': 4, 'John_Mulaney': 5, 'John_Mulaney_2': 4, 'Jimmy_Yang': 2, 'Jimmy_Yang_2': 4, 'Louis_CK': 5, 'Louis_CK_2': 4, 'Nate_Bargatze': 3, 'Nate_Bargatze_2': 4, 'Nate_Bargatze_TK': 4, 'Nate_Bargatze_TK_2': 5, 'Russell_Peters': 4, 'Russell_Peters_2': 5, 'Sam_Morril': 2, 'Sam_Morril_2': 4, 'Trevor_Noah': 2, 'Trevor_Noah_2': 3, 'Tom_Segura': 5, 'Tom_Segura_2': 2}\n"
     ]
    }
   ],
   "source": [
    "quotes_count_dict = {}\n",
    "for comedian in model['Comedian']:\n",
    "    if comedian in quotes_count_dict:\n",
    "        quotes_count_dict[comedian] += 1\n",
    "    else:\n",
    "        quotes_count_dict[comedian] = 1\n",
    "\n",
    "print(quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = {}\n",
    "\n",
    "for index, row in model.iterrows():\n",
    "    comedian_name = row['Comedian']\n",
    "    model_output = row['Sentence']   \n",
    "    simple_model_output = simple_sentence(model_output)\n",
    "    matching = ground_truth[ground_truth['comedian'] == comedian_name]\n",
    "\n",
    "    if truth not in found:\n",
    "        found[model_output] = [comedian_name, 0]  \n",
    "\n",
    "    for index2, row2 in matching.iterrows():\n",
    "        truth = row2['sentence']\n",
    "        simple_truth = simple_sentence(truth)\n",
    "\n",
    "        if simple_truth == simple_model_output or simple_model_output in simple_truth:\n",
    "            found[model_output][0] = comedian_name  \n",
    "            found[model_output][1] = 100\n",
    "        else:\n",
    "            fuzzy_score = fuzz.partial_ratio(simple_truth, simple_model_output)\n",
    "            if fuzzy_score > 60:\n",
    "                found[model_output][0] = comedian_name \n",
    "                found[model_output][1] = max(found[model_output][1], fuzzy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(found, num_sentences):\n",
    "    correct_guesses = {}\n",
    "    \n",
    "    for val in found.values():\n",
    "        comedian_name = val[0]\n",
    "        if comedian_name not in correct_guesses:\n",
    "            correct_guesses[comedian_name] = val[1]\n",
    "        else:\n",
    "            correct_guesses[comedian_name] += val[1]\n",
    "    \n",
    "    for comedian_name, score in correct_guesses.items():\n",
    "        correct_guesses[comedian_name] = (correct_guesses[comedian_name]/num_sentences[comedian_name]) \n",
    "        \n",
    "    return correct_guesses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found, quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': 100.0,\n",
       " 'Anthony_Jeselnik_2': 66.0,\n",
       " 'Ali_Wong': 42.25,\n",
       " 'Ali_Wong_2': 66.66666666666667,\n",
       " 'Chelsea_Peretti': 56.333333333333336,\n",
       " 'Chelsea_Peretti_2': 50.0,\n",
       " 'Donald_Glover': 30.333333333333332,\n",
       " 'Donald_Glover_2': 82.66666666666667,\n",
       " 'Hasan_Minhaj': 75.0,\n",
       " 'Hasan_Minhaj_2': 50.0,\n",
       " 'Iliza_Shlesinger': 66.66666666666667,\n",
       " 'Iliza_Shlesinger_2': 81.0,\n",
       " 'Jim_Gaffigan': 87.25,\n",
       " 'Jim_Gaffigan_2': 54.0,\n",
       " 'Joe_List': 67.25,\n",
       " 'Joe_List_2': 25.0,\n",
       " 'John_Mulaney': 77.0,\n",
       " 'John_Mulaney_2': 42.75,\n",
       " 'Jimmy_Yang': 50.0,\n",
       " 'Jimmy_Yang_2': 75.0,\n",
       " 'Louis_CK': 100.0,\n",
       " 'Louis_CK_2': 65.25,\n",
       " 'Nate_Bargatze': 60.333333333333336,\n",
       " 'Nate_Bargatze_2': 15.25,\n",
       " 'Nate_Bargatze_TK': 99.5,\n",
       " 'Nate_Bargatze_TK_2': 20.0,\n",
       " 'Russell_Peters': 74.25,\n",
       " 'Russell_Peters_2': 60.0,\n",
       " 'Sam_Morril': 97.0,\n",
       " 'Sam_Morril_2': 25.0,\n",
       " 'Trevor_Noah': 46.0,\n",
       " 'Trevor_Noah_2': 93.66666666666667,\n",
       " 'Tom_Segura': 73.4,\n",
       " 'Tom_Segura_2': 50.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    filtered_sentence = []\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_metric(model_output, ground_truth):\n",
    "    found = {}\n",
    "\n",
    "    for index, row in model.iterrows():\n",
    "        comedian_name = row['Comedian']\n",
    "        model_output = row['Sentence']   \n",
    "        simple_model_output = simple_sentence(model_output)\n",
    "        matching = ground_truth[ground_truth['comedian'] == comedian_name]\n",
    "\n",
    "        if model_output not in found:\n",
    "            found[model_output] = [comedian_name, 0]  \n",
    "\n",
    "        for index2, row2 in matching.iterrows():\n",
    "            truth = row2['sentence']\n",
    "            simple_truth = simple_sentence(truth)\n",
    "            stop_model = remove_stop_words(simple_model_output)\n",
    "            stop_truth = remove_stop_words(simple_truth)\n",
    "            if simple_truth == simple_model_output or stop_model in stop_truth:\n",
    "                found[model_output][0] = comedian_name  \n",
    "                found[model_output][1] = 100\n",
    "            else:\n",
    "                fuzzy_score = fuzz.partial_ratio(stop_truth, stop_model)\n",
    "                if fuzzy_score > 60:\n",
    "                    found[model_output][0] = comedian_name \n",
    "                    found[model_output][1] = max(found[model_output][1], fuzzy_score)\n",
    "        \n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = base_metric(model, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(found, num_sentences):\n",
    "    correct_guesses = {}\n",
    "    \n",
    "    for val in found.values():\n",
    "        comedian_name = val[0]\n",
    "        if comedian_name not in correct_guesses:\n",
    "            correct_guesses[comedian_name] = val[1]\n",
    "        else:\n",
    "            correct_guesses[comedian_name] += val[1]\n",
    "    \n",
    "    for comedian_name, score in correct_guesses.items():\n",
    "        correct_guesses[comedian_name] = (correct_guesses[comedian_name]/num_sentences[comedian_name]) \n",
    "        \n",
    "    return correct_guesses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found, quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': 100.0,\n",
       " 'Anthony_Jeselnik_2': 66.66666666666667,\n",
       " 'Ali_Wong': 42.0,\n",
       " 'Ali_Wong_2': 66.66666666666667,\n",
       " 'Chelsea_Peretti': 33.333333333333336,\n",
       " 'Chelsea_Peretti_2': 50.0,\n",
       " 'Donald_Glover': 30.0,\n",
       " 'Donald_Glover_2': 80.66666666666667,\n",
       " 'Hasan_Minhaj': 75.0,\n",
       " 'Hasan_Minhaj_2': 50.0,\n",
       " 'Iliza_Shlesinger': 66.66666666666667,\n",
       " 'Iliza_Shlesinger_2': 50.0,\n",
       " 'Jim_Gaffigan': 87.75,\n",
       " 'Jim_Gaffigan_2': 55.333333333333336,\n",
       " 'Joe_List': 83.25,\n",
       " 'Joe_List_2': 25.0,\n",
       " 'John_Mulaney': 78.4,\n",
       " 'John_Mulaney_2': 61.25,\n",
       " 'Jimmy_Yang': 50.0,\n",
       " 'Jimmy_Yang_2': 75.0,\n",
       " 'Louis_CK': 100.0,\n",
       " 'Louis_CK_2': 65.25,\n",
       " 'Nate_Bargatze': 62.666666666666664,\n",
       " 'Nate_Bargatze_2': 33.0,\n",
       " 'Nate_Bargatze_TK': 99.0,\n",
       " 'Nate_Bargatze_TK_2': 20.0,\n",
       " 'Russell_Peters': 72.5,\n",
       " 'Russell_Peters_2': 88.6,\n",
       " 'Sam_Morril': 100.0,\n",
       " 'Sam_Morril_2': 42.5,\n",
       " 'Trevor_Noah': 45.5,\n",
       " 'Trevor_Noah_2': 94.66666666666667,\n",
       " 'Tom_Segura': 60.0,\n",
       " 'Tom_Segura_2': 50.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = pd.read_csv('/home/ada/humor/humor/standup_transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = []\n",
    "\n",
    "for i in range(len(transcript['comedian'])):\n",
    "    comedian = transcript['comedian'][i]\n",
    "    trans = transcript['transcript'][i]\n",
    "    sentences = nltk.sent_tokenize(trans)\n",
    "    selected = random.sample(sentences, min(3, len(sentences)))\n",
    "    \n",
    "    for sentence in selected:\n",
    "        random_sentences.append({'comedian': comedian, 'sentence': sentence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedian</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>And we never talk, write letters or any of tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>I think.I mean, don’t get me wrong, I loved my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony_Jeselnik</td>\n",
       "      <td>We fought a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>She would read Mark Twain to me, and I loved it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony_Jeselnik_2</td>\n",
       "      <td>When I was like four years old, before I learn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             comedian                                           sentence\n",
       "0    Anthony_Jeselnik  And we never talk, write letters or any of tha...\n",
       "1    Anthony_Jeselnik  I think.I mean, don’t get me wrong, I loved my...\n",
       "2    Anthony_Jeselnik                                   We fought a lot.\n",
       "3  Anthony_Jeselnik_2   She would read Mark Twain to me, and I loved it.\n",
       "4  Anthony_Jeselnik_2  When I was like four years old, before I learn..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test = pd.DataFrame(random_sentences)\n",
    "base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = base_metric(model, base_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_guesses = calculate_score(found, quotes_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthony_Jeselnik': 0.0,\n",
       " 'Anthony_Jeselnik_2': 32.0,\n",
       " 'Ali_Wong': 50.0,\n",
       " 'Ali_Wong_2': 0.0,\n",
       " 'Chelsea_Peretti': 0.0,\n",
       " 'Chelsea_Peretti_2': 25.0,\n",
       " 'Donald_Glover': 33.333333333333336,\n",
       " 'Donald_Glover_2': 0.0,\n",
       " 'Hasan_Minhaj': 17.0,\n",
       " 'Hasan_Minhaj_2': 43.75,\n",
       " 'Iliza_Shlesinger': 0.0,\n",
       " 'Iliza_Shlesinger_2': 0.0,\n",
       " 'Jim_Gaffigan': 64.75,\n",
       " 'Jim_Gaffigan_2': 33.333333333333336,\n",
       " 'Joe_List': 42.5,\n",
       " 'Joe_List_2': 0.0,\n",
       " 'John_Mulaney': 53.4,\n",
       " 'John_Mulaney_2': 36.25,\n",
       " 'Jimmy_Yang': 50.0,\n",
       " 'Jimmy_Yang_2': 25.0,\n",
       " 'Louis_CK': 52.2,\n",
       " 'Louis_CK_2': 20.0,\n",
       " 'Nate_Bargatze': 66.66666666666667,\n",
       " 'Nate_Bargatze_2': 16.25,\n",
       " 'Nate_Bargatze_TK': 25.0,\n",
       " 'Nate_Bargatze_TK_2': 17.8,\n",
       " 'Russell_Peters': 40.75,\n",
       " 'Russell_Peters_2': 40.0,\n",
       " 'Sam_Morril': 0.0,\n",
       " 'Sam_Morril_2': 16.75,\n",
       " 'Trevor_Noah': 32.5,\n",
       " 'Trevor_Noah_2': 29.0,\n",
       " 'Tom_Segura': 47.4,\n",
       " 'Tom_Segura_2': 0.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_guesses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
